{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/judem-21/Seq2Seq-Model/blob/main/Seq2Seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1PolMPZOEbE"
      },
      "source": [
        "#Seq2Seq Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF7XsLNXhz7V"
      },
      "source": [
        "###Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "me-hNcwXhajQ"
      },
      "outputs": [],
      "source": [
        "import torch,torchvision\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms as transforms\n",
        "#from torch.torchmetrics.text.bleu import BLEUScore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QrDUgehUhzUU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from skimage import io\n",
        "import spacy\n",
        "from PIL import Image\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en\n",
        "!python -m spacy download de_core_news_sm\n",
        "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
        "spacy_ger = spacy.load(\"de_core_news_sm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V6nyChz-yl9",
        "outputId": "2722b009-0d24-4bb2-c379-2917fc5f6dca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting de-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbkXCOiHiKAk"
      },
      "source": [
        "###Dataset (Loading and Testing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNytP7BRN1QL"
      },
      "source": [
        "####Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAJmpQHviJOU",
        "outputId": "69070ea2-e85c-4ff4-f0b9-82cba2802e66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2ScqFknWkYHX"
      },
      "outputs": [],
      "source": [
        "class Vocabulary:\n",
        "    def __init__(self, freq_threshold=3):\n",
        "        self.itos_source = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
        "        self.stoi_source = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
        "\n",
        "        self.itos_target = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
        "        self.stoi_target = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
        "\n",
        "        self.punctuation_marks = [\n",
        "    '.', ',', ';', ':', '!', '?', '-', '—', '(', ')', '[', ']', '{', '}',\n",
        "    \"'\", '\"', '...', '“', '”', '‘', '’', '/', '\\\\', '|', '@', '#', '$', '%',\n",
        "    '^', '&', '*', '_', '=', '+', '<', '>', '`', '~'\n",
        "]\n",
        "\n",
        "        self.freq_threshold = freq_threshold\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.itos)\n",
        "\n",
        "    @staticmethod\n",
        "    def tokenizer(text,key):\n",
        "      if key=='en':\n",
        "        return [tok.text.lower() for tok in spacy_eng.tokenizer(text)]\n",
        "      else:\n",
        "        return [tok.text.lower() for tok in spacy_ger.tokenizer(text)]\n",
        "\n",
        "    def build_vocabulary(self, sentence_list, key):\n",
        "        frequencies = {}\n",
        "        idx = 4\n",
        "\n",
        "        for sentence in sentence_list:\n",
        "          if key=='source': lookup=self.tokenizer(sentence,'de')\n",
        "          else: lookup=self.tokenizer(sentence,'en')\n",
        "\n",
        "          for word in lookup:\n",
        "            if word=='\\n' or word in self.punctuation_marks: continue\n",
        "\n",
        "            if word not in frequencies:\n",
        "              frequencies[word] = 1\n",
        "\n",
        "            else:\n",
        "              frequencies[word] += 1\n",
        "\n",
        "            if frequencies[word] == self.freq_threshold:\n",
        "              if key=='source':\n",
        "                self.stoi_source[word] = idx\n",
        "                self.itos_source[idx] = word\n",
        "              elif key=='target':\n",
        "                self.stoi_target[word] = idx\n",
        "                self.itos_target[idx] = word\n",
        "              idx += 1\n",
        "\n",
        "    def numericalize(self, text,key):\n",
        "        if key=='source':\n",
        "          tokenized_text = self.tokenizer(text,'de')\n",
        "          return [self.stoi_source[token] if token in self.stoi_source else self.stoi_source[\"<UNK>\"] for token in tokenized_text]\n",
        "        elif key=='target':\n",
        "          tokenized_text = self.tokenizer(text,'en')\n",
        "          return [self.stoi_target[token] if token in self.stoi_target else self.stoi_target[\"<UNK>\"] for token in tokenized_text]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class seq2seq_dataset(Dataset):\n",
        "    def __init__(self,dataset_path, num_samples=29000, freq_threshold=3):\n",
        "        self.df = pd.read_csv(dataset_path,delimiter='\\t',names=['English','German']).values\n",
        "        self.num_samples=num_samples\n",
        "\n",
        "        self.idx_sentences_source= {}\n",
        "        self.idx_sentences_target= {}\n",
        "\n",
        "        self.punctuation_marks = [\n",
        "    '.', ',', ';', ':', '!', '?', '-', '—', '(', ')', '[', ']', '{', '}',\n",
        "    \"'\", '\"', '...', '“', '”', '‘', '’', '/', '\\\\', '|', '@', '#', '$', '%',\n",
        "    '^', '&', '*', '_', '=', '+', '<', '>', '`', '~'\n",
        "]\n",
        "\n",
        "        idx=0\n",
        "        for row in self.df:\n",
        "            source_sentence = row[1]\n",
        "            #if 'Tom' in source_sentence: continue\n",
        "\n",
        "            target_sentence = row[0]\n",
        "\n",
        "            if source_sentence[-1] in self.punctuation_marks: source_sentence=source_sentence[:-1]\n",
        "            if target_sentence[-1] in self.punctuation_marks: target_sentence=target_sentence[:-1]\n",
        "\n",
        "            self.idx_sentences_source[idx]=source_sentence\n",
        "            self.idx_sentences_target[idx]=target_sentence\n",
        "\n",
        "            idx+=1\n",
        "            if idx==self.num_samples: break\n",
        "\n",
        "\n",
        "        self.vocab = Vocabulary(freq_threshold)\n",
        "        self.vocab.build_vocabulary(self.idx_sentences_source.values(),'source')\n",
        "        self.vocab.build_vocabulary(self.idx_sentences_target.values(),'target')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx_sentences_source)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        source_sentence = self.idx_sentences_source[index]\n",
        "        target_sentence = self.idx_sentences_target[index]\n",
        "\n",
        "        #numericalised source sentence\n",
        "        numericalized_caption_source= [self.vocab.stoi_source[\"<SOS>\"]] + self.vocab.numericalize(source_sentence,key='source') + [self.vocab.stoi_source[\"<EOS>\"]]\n",
        "\n",
        "        #numericalised target sentence\n",
        "        numericalized_caption_target= [self.vocab.stoi_target[\"<SOS>\"]] + self.vocab.numericalize(target_sentence,key='target') + [self.vocab.stoi_target[\"<EOS>\"]]\n",
        "\n",
        "        return torch.tensor(numericalized_caption_source), torch.tensor(numericalized_caption_target)"
      ],
      "metadata": {
        "id": "ECG_R0CASSEO"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TdSpUVlX_oZl"
      },
      "outputs": [],
      "source": [
        "class MyCollate:\n",
        "    def __init__(self, pad_idx):\n",
        "        self.pad_idx = pad_idx\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        sources=[item[0] for item in batch]\n",
        "        sources=pad_sequence(sources, batch_first=False, padding_value=self.pad_idx)\n",
        "\n",
        "        targets = [item[1] for item in batch]\n",
        "        targets = pad_sequence(targets, batch_first=False, padding_value=self.pad_idx)\n",
        "\n",
        "        return sources, targets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loader(\n",
        "    dataset_path,num_samples=28000,\n",
        "    freq_threshold=2,\n",
        "    batch_size=32,\n",
        "    num_workers=8,\n",
        "    shuffle=True,\n",
        "    pin_memory=True,\n",
        "):\n",
        "    dataset = seq2seq_dataset(dataset_path=dataset_path, num_samples=num_samples,freq_threshold=freq_threshold)\n",
        "\n",
        "    pad_idx = dataset.vocab.stoi_source[\"<PAD>\"]\n",
        "\n",
        "    loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        shuffle=shuffle,\n",
        "        pin_memory=pin_memory,\n",
        "        collate_fn=MyCollate(pad_idx=pad_idx),\n",
        "    )\n",
        "\n",
        "    return loader, dataset"
      ],
      "metadata": {
        "id": "8HGNLSQhUIq6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WLXCdb3_pMQ"
      },
      "source": [
        "####Dataset Testing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, dataset = get_loader(dataset_path='/content/drive/MyDrive/Seq2SeqModel/dataset.txt',\n",
        "                                   num_samples=99968,freq_threshold=2,batch_size=64,num_workers=2)"
      ],
      "metadata": {
        "id": "IcRHL1qCWK6H"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfEbFkuEWffw",
        "outputId": "198b5877-68c8-4ca4-b044-5f201c6fd990"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99968"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_idx,(sources,targets) in enumerate(train_loader):\n",
        "  break"
      ],
      "metadata": {
        "id": "V2YNOdxjyBaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4179db69-07f8-4122-bd8e-ab3e6836b8f0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkP74uHvGTmV",
        "outputId": "5b5025c7-d7d4-4de2-9b99-4d048c55fe5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch no.: 6:-\n",
            "Sample 9 of Batch 6\n",
            "Source Shape: torch.Size([11, 64])\n",
            "Target Shape: torch.Size([11, 64])\n",
            "Source Sentence: \"<SOS> wie alt schätzt ihr sie <EOS> <PAD> <PAD> <PAD> <PAD>\" with length: 11\n",
            "Target Sentence: \"<SOS> how old do you think she is <EOS> <PAD> <PAD>\" with length: 11\n"
          ]
        }
      ],
      "source": [
        "batch_chk_idx=5\n",
        "for batch_idx,(sources,targets) in enumerate(train_loader):\n",
        "  if batch_idx==batch_chk_idx:break\n",
        "print(f'Batch no.: {batch_idx+1}:-')\n",
        "\n",
        "source_sentence=''\n",
        "num_words_source=0\n",
        "chk_idx=8\n",
        "\n",
        "print(f'Sample {chk_idx+1} of Batch {batch_idx+1}')\n",
        "print(f'Source Shape: {sources.shape}')\n",
        "print(f'Target Shape: {targets.shape}')\n",
        "\n",
        "for source_idx in sources[:,chk_idx]:\n",
        "  num_words_source+=1\n",
        "  source_sentence+=dataset.vocab.itos_source[source_idx.item()]+' '\n",
        "\n",
        "target_sentence=''\n",
        "num_words_target=0\n",
        "for target_idx in targets[:,chk_idx]:\n",
        "  num_words_target+=1\n",
        "  target_sentence+=dataset.vocab.itos_target[target_idx.item()]+' '\n",
        "source_sentence=source_sentence[:-1]\n",
        "target_sentence=target_sentence[:-1]\n",
        "\n",
        "print(f'Source Sentence: \"{source_sentence}\" with length: {num_words_source}')\n",
        "print(f'Target Sentence: \"{target_sentence}\" with length: {num_words_target}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhCm_g3AHg2C",
        "outputId": "93363eff-0261-4801-c43f-8ae54c826349"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "'\\n' in dataset.vocab.itos_target"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model"
      ],
      "metadata": {
        "id": "Tbk3wodxN2XJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,vocab_size,num_layers=1):\n",
        "    super(EncoderRNN,self).__init__()\n",
        "    self.embed=nn.Embedding(num_embeddings=vocab_size,embedding_dim=input_size)\n",
        "    self.lstm=nn.LSTM(input_size=input_size,hidden_size=hidden_size,num_layers=num_layers,dropout=0.5)\n",
        "    self.dropout=nn.Dropout(p=0.5)\n",
        "\n",
        "\n",
        "  def forward(self,source_sentence):\n",
        "    #source_sentence dim: (seq_len,batch)\n",
        "\n",
        "    embeddings=self.dropout(self.embed(source_sentence))\n",
        "    #embeddings dim: (seq_len,batch,input_size)\n",
        "\n",
        "    outputs,(hidden_state,cell_state)=self.lstm(embeddings)\n",
        "    #output dim: (seq_len,batch,hidden_size)\n",
        "    #hidden_state/cell_state dim: (num_layers,batch,hidden_size)\n",
        "\n",
        "    return hidden_state,cell_state"
      ],
      "metadata": {
        "id": "euxh54p5BVLT"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,vocab_size,num_layers=1):\n",
        "    super(DecoderRNN,self).__init__()\n",
        "    self.embed=nn.Embedding(num_embeddings=vocab_size,embedding_dim=input_size)\n",
        "    self.lstm=nn.LSTM(input_size=input_size,hidden_size=hidden_size,num_layers=num_layers,dropout=0.5)\n",
        "    self.linear=nn.Linear(in_features=hidden_size,out_features=vocab_size)\n",
        "    self.dropout=nn.Dropout(p=0.5)\n",
        "\n",
        "\n",
        "  def forward(self,word_idx,hidden_state,cell_state):\n",
        "    #word_vector dim: (batch,)\n",
        "    #hidden_state/cell_state dim: (num_layers,batch,hidden_size)\n",
        "\n",
        "    embedding=self.dropout(self.embed(word_idx.unsqueeze(0)))\n",
        "    #embeddingdim: (1,batch,input_size)\n",
        "\n",
        "    output,(hidden_state,cell_state)=self.lstm(embedding,(hidden_state,cell_state))\n",
        "    #output dim: (1,batch,hidden_size)\n",
        "    #hidden_state/cell_state dim: (num_layers,batch,hidden_size)\n",
        "\n",
        "    predicted_word=self.linear(output).squeeze(0)\n",
        "    #predicted_word dim: (batch,vocab_size)\n",
        "\n",
        "    return predicted_word,hidden_state,cell_state"
      ],
      "metadata": {
        "id": "rji1avkrBY8V"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,vocab_size_source,vocab_size_target,num_layers=1):\n",
        "    super(Seq2Seq,self).__init__()\n",
        "    self.encoder=EncoderRNN(input_size=input_size,hidden_size=hidden_size,vocab_size=vocab_size_source,num_layers=num_layers)\n",
        "    self.decoder=DecoderRNN(input_size=input_size,hidden_size=hidden_size,vocab_size=vocab_size_target,num_layers=num_layers)\n",
        "    self.vocab_size_source=vocab_size_source\n",
        "    self.vocab_size_target=vocab_size_target\n",
        "\n",
        "  def forward(self,source_sentences,target_sentences,teacher_forcer_ratio=0.5):\n",
        "    #source/target sentence dim: (seq_len,batch)\n",
        "\n",
        "    hidden_state,cell_state=self.encoder(source_sentences)\n",
        "    #hidden_state/cell_state dim: (num_layers,batch,hidden_size)\n",
        "\n",
        "    target_len,batch_size=target_sentences.shape\n",
        "    outputs=torch.zeros(size=(target_len,batch_size,self.vocab_size_target))\n",
        "    input_word=target_sentences[0]\n",
        "    #input_word dim: (batch, )\n",
        "\n",
        "    for idx in range(1,target_len):\n",
        "      prediction,hidden_state,cell_state=self.decoder(input_word,hidden_state,cell_state)\n",
        "      outputs[idx]=prediction\n",
        "\n",
        "      if random.random()<teacher_forcer_ratio:\n",
        "        input_word=target_sentences[idx]\n",
        "      else:\n",
        "        input_word=prediction.argmax(dim=1)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "  def translate(self,source_sentence,vocab_target,device,max_len=50):\n",
        "    #source_sentence dim: (seq_len,)\n",
        "\n",
        "    hidden_state,cell_state=self.encoder(source_sentence.unsqueeze(1).to(device))\n",
        "    #hidden_state/cell_state dim: (num_layers,batch,hidden_size)\n",
        "\n",
        "    translated='<SOS> '\n",
        "    input_word=torch.tensor([source_sentence[0].item(),])\n",
        "    #input_word dim: (1,)\n",
        "\n",
        "    for pred in range(max_len):\n",
        "      prediction,hidden_state,cell_state=self.decoder(input_word.to(device),hidden_state.to(device),cell_state.to(device))\n",
        "      #prediction dim: (1,vocab_size)\n",
        "\n",
        "      word_idx=prediction.argmax(dim=1)\n",
        "      #word_idx dim: (1,)\n",
        "\n",
        "      translated+=vocab_target[word_idx.item()]+' '\n",
        "\n",
        "      if vocab_target[word_idx.item()]=='<EOS>': break\n",
        "\n",
        "      input_word=torch.tensor([word_idx.item(),])\n",
        "\n",
        "    return translated[:-1]\n"
      ],
      "metadata": {
        "id": "6eL5QRxtBtOR"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training"
      ],
      "metadata": {
        "id": "_GchhGtKFMnf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialisation"
      ],
      "metadata": {
        "id": "elGuVpXGGyVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#hyper-parameters\n",
        "num_epochs=40\n",
        "lr=1e-3\n",
        "batch_size=64\n",
        "input_size,hidden_size=256,1024\n",
        "num_samples=99968\n",
        "num_layers=1\n",
        "freq_threshold=2\n",
        "dataset_path='/content/drive/MyDrive/Seq2SeqModel/dataset.txt'\n",
        "\n",
        "#dataset\n",
        "'''train_loader, dataset = get_loader(source_file=source_file,\n",
        "                                   target_file=target_file,\n",
        "                                   num_samples=num_samples,freq_threshold=freq_threshold,batch_size=batch_size,num_workers=2)'''\n",
        "train_loader,dataset=get_loader(dataset_path=dataset_path,num_samples=num_samples,freq_threshold=freq_threshold,batch_size=batch_size)\n",
        "\n",
        "#model\n",
        "#min_loss=np.Inf\n",
        "save_path='/content/drive/MyDrive/Seq2SeqModel/model'\n",
        "model=Seq2Seq(input_size=input_size,hidden_size=hidden_size,vocab_size_source=len(dataset.vocab.itos_source),vocab_size_target=len(dataset.vocab.itos_target),num_layers=num_layers).to(device)\n",
        "min_loss=torch.load('/content/drive/MyDrive/Seq2SeqModel/model.pth',map_location=device)['loss']\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Seq2SeqModel/model.pth',map_location=device)['model_state_dict'])\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=lr)\n",
        "criterion=nn.CrossEntropyLoss(ignore_index=dataset.vocab.stoi_target['<PAD>'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Usd0XPRWzzr",
        "outputId": "21e9368a-66d3-46ff-ad6b-2561cd5acbc8"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hwG_stpSLRa",
        "outputId": "cd08c515-1dff-4d34-ec34-4a284f821120"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6902420901038735"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#validation sentence\n",
        "chk_idx=25000\n",
        "source,target=dataset[chk_idx]\n",
        "\n",
        "validation_sentence_source=''\n",
        "for word_idx in source:\n",
        "  validation_sentence_source+=dataset.vocab.itos_source[word_idx.item()]+' '\n",
        "print(f'Source sentence: {validation_sentence_source[:-1]}')\n",
        "\n",
        "validation_sentence_target=''\n",
        "for word_idx in target:\n",
        "  validation_sentence_target+=dataset.vocab.itos_target[word_idx.item()]+' '\n",
        "print(f'Target sentence: {validation_sentence_target[:-1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYH_4e1Ame-p",
        "outputId": "107853fc-abed-4a5b-c279-c767c5f07172"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source sentence: <SOS> bitte setzen sie sich <EOS>\n",
            "Target sentence: <SOS> please have a seat <EOS>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Checkpoint"
      ],
      "metadata": {
        "id": "ZSF6N4-sULqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(epoch,model,loss,optimiser,path):\n",
        "  save_path=path+'.pth'\n",
        "  torch.save({\n",
        "      'epoch':epoch,\n",
        "      'model_state_dict':model.state_dict(),\n",
        "      'optimizer_state_dict':optimiser.state_dict(),\n",
        "      'loss':loss\n",
        "  },save_path)"
      ],
      "metadata": {
        "id": "9kysYvj6ULTL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Block"
      ],
      "metadata": {
        "id": "alBtUxKNG0qO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Actual sentence: {validation_sentence_target[:-1]}')\n",
        "epoch_losses=[]\n",
        "model.train()\n",
        "num_batches=len(train_loader)\n",
        "for epoch in range(1,num_epochs+1):\n",
        "  batch_losses=[]\n",
        "  print(f'Epoch {epoch} begins:-\\n')\n",
        "  for batch_idx,(source_sentences,target_sentences) in enumerate(train_loader):\n",
        "    inputs=source_sentences.to(device)\n",
        "    targets=target_sentences.to(device)\n",
        "\n",
        "    outputs=model(inputs,targets).to(device)\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss=criterion(outputs[1:].reshape(-1,outputs.shape[2]),targets[1:].reshape(-1))\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(),max_norm=1)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    batch_losses.append(loss.item())\n",
        "\n",
        "    if (batch_idx+1)%100==0:\n",
        "      print(f'Epoch {epoch}/{num_epochs}, Batch {batch_idx+1}/{num_batches}, Batch Loss: {batch_losses[-1]:.4f}')\n",
        "\n",
        "      translated_sentence=model.translate(source.to(device),dataset.vocab.itos_target,device)\n",
        "      print(f'Translated sentence: {translated_sentence}\\n')\n",
        "\n",
        "  epoch_losses.append(np.mean(batch_losses))\n",
        "  print(f'\\nEpoch {epoch}/{num_epochs}, Epoch Loss: {epoch_losses[-1]:.4f}')\n",
        "  current_epoch_loss=epoch_losses[-1]\n",
        "  if current_epoch_loss<min_loss:\n",
        "    print(f'Epoch Loss improved from {min_loss:.4f} to {current_epoch_loss:.4f}')\n",
        "    min_loss=current_epoch_loss\n",
        "    save_checkpoint(epoch,model,current_epoch_loss,optimizer,save_path)\n",
        "    print(f'Improved Model saved at \"{save_path}\"\\n')\n",
        "\n",
        "\n",
        "  print(f'Epoch {epoch} ends!!\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfciZM3JGxhG",
        "outputId": "ba963f41-5e85-42d6-ad6b-76873bbfd444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual sentence: <SOS> please have a seat <EOS>\n",
            "Epoch 1 begins:-\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40, Batch 100/1562, Batch Loss: 4.8075\n",
            "Translated sentence: <SOS>i 's n't you <EOS>\n",
            "\n",
            "Epoch 1/40, Batch 200/1562, Batch Loss: 4.3914\n",
            "Translated sentence: <SOS>tom is a <EOS>\n",
            "\n",
            "Epoch 1/40, Batch 300/1562, Batch Loss: 4.1464\n",
            "Translated sentence: <SOS>you 're <EOS>\n",
            "\n",
            "Epoch 1/40, Batch 400/1562, Batch Loss: 4.0596\n",
            "Translated sentence: <SOS>the <UNK> <EOS>\n",
            "\n",
            "Epoch 1/40, Batch 500/1562, Batch Loss: 4.0774\n",
            "Translated sentence: <SOS>please me <EOS>\n",
            "\n",
            "Epoch 1/40, Batch 600/1562, Batch Loss: 3.4407\n",
            "Translated sentence: <SOS>please <UNK> <EOS>\n",
            "\n",
            "Epoch 1/40, Batch 700/1562, Batch Loss: 3.3699\n",
            "Translated sentence: <SOS>please you <EOS>\n",
            "\n",
            "Epoch 1/40, Batch 800/1562, Batch Loss: 3.5245\n",
            "Translated sentence: <SOS>please you <EOS>\n",
            "\n",
            "Epoch 1/40, Batch 900/1562, Batch Loss: 3.1944\n",
            "Translated sentence: <SOS>please please <EOS>\n",
            "\n",
            "Epoch 1/40, Batch 1000/1562, Batch Loss: 2.9826\n",
            "Translated sentence: <SOS>please please <EOS>\n",
            "\n",
            "Epoch 1/40, Batch 1100/1562, Batch Loss: 2.7033\n",
            "Translated sentence: <SOS>please please <EOS>\n",
            "\n",
            "Epoch 1/40, Batch 1200/1562, Batch Loss: 3.0432\n",
            "Translated sentence: <SOS>please you <EOS>\n",
            "\n",
            "Epoch 1/40, Batch 1300/1562, Batch Loss: 3.1568\n",
            "Translated sentence: <SOS>please please <EOS>\n",
            "\n",
            "Epoch 1/40, Batch 1400/1562, Batch Loss: 2.9742\n",
            "Translated sentence: <SOS>please do you <EOS>\n",
            "\n",
            "Epoch 1/40, Batch 1500/1562, Batch Loss: 2.9384\n",
            "Translated sentence: <SOS>please you <EOS>\n",
            "\n",
            "\n",
            "Epoch 1/40, Epoch Loss: 3.6054\n",
            "Epoch Loss improved from inf to 3.6054\n",
            "Improved Model saved at \"/content/drive/MyDrive/Seq2SeqModel/model\"\n",
            "\n",
            "Epoch 1 ends!!\n",
            "\n",
            "\n",
            "Epoch 2 begins:-\n",
            "\n",
            "Epoch 2/40, Batch 100/1562, Batch Loss: 2.6083\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 2/40, Batch 200/1562, Batch Loss: 2.5458\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 2/40, Batch 300/1562, Batch Loss: 2.4410\n",
            "Translated sentence: <SOS>please come down <EOS>\n",
            "\n",
            "Epoch 2/40, Batch 400/1562, Batch Loss: 2.4479\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 2/40, Batch 500/1562, Batch Loss: 2.4421\n",
            "Translated sentence: <SOS>please please <EOS>\n",
            "\n",
            "Epoch 2/40, Batch 600/1562, Batch Loss: 2.5947\n",
            "Translated sentence: <SOS>please come away <EOS>\n",
            "\n",
            "Epoch 2/40, Batch 700/1562, Batch Loss: 2.4482\n",
            "Translated sentence: <SOS>please call <EOS>\n",
            "\n",
            "Epoch 2/40, Batch 800/1562, Batch Loss: 2.5916\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 2/40, Batch 900/1562, Batch Loss: 2.2894\n",
            "Translated sentence: <SOS>please come <EOS>\n",
            "\n",
            "Epoch 2/40, Batch 1000/1562, Batch Loss: 2.2400\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 2/40, Batch 1100/1562, Batch Loss: 2.2680\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 2/40, Batch 1200/1562, Batch Loss: 2.4036\n",
            "Translated sentence: <SOS>please hurry <EOS>\n",
            "\n",
            "Epoch 2/40, Batch 1300/1562, Batch Loss: 2.1377\n",
            "Translated sentence: <SOS>please hurry <EOS>\n",
            "\n",
            "Epoch 2/40, Batch 1400/1562, Batch Loss: 2.2100\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 2/40, Batch 1500/1562, Batch Loss: 2.0910\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "\n",
            "Epoch 2/40, Epoch Loss: 2.4368\n",
            "Epoch Loss improved from 3.6054 to 2.4368\n",
            "Improved Model saved at \"/content/drive/MyDrive/Seq2SeqModel/model\"\n",
            "\n",
            "Epoch 2 ends!!\n",
            "\n",
            "\n",
            "Epoch 3 begins:-\n",
            "\n",
            "Epoch 3/40, Batch 100/1562, Batch Loss: 1.9292\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 3/40, Batch 200/1562, Batch Loss: 2.1046\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 3/40, Batch 300/1562, Batch Loss: 2.0445\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 3/40, Batch 400/1562, Batch Loss: 2.1003\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 3/40, Batch 500/1562, Batch Loss: 2.0557\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 3/40, Batch 600/1562, Batch Loss: 1.9056\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 3/40, Batch 700/1562, Batch Loss: 2.0796\n",
            "Translated sentence: <SOS>please hurry up <EOS>\n",
            "\n",
            "Epoch 3/40, Batch 800/1562, Batch Loss: 1.9486\n",
            "Translated sentence: <SOS>please hurry <EOS>\n",
            "\n",
            "Epoch 3/40, Batch 900/1562, Batch Loss: 2.1403\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 3/40, Batch 1000/1562, Batch Loss: 2.0795\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 3/40, Batch 1100/1562, Batch Loss: 1.9120\n",
            "Translated sentence: <SOS>please hurry <EOS>\n",
            "\n",
            "Epoch 3/40, Batch 1200/1562, Batch Loss: 1.8422\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 3/40, Batch 1300/1562, Batch Loss: 2.1387\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 3/40, Batch 1400/1562, Batch Loss: 1.6670\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 3/40, Batch 1500/1562, Batch Loss: 1.7130\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "\n",
            "Epoch 3/40, Epoch Loss: 1.9421\n",
            "Epoch Loss improved from 2.4368 to 1.9421\n",
            "Improved Model saved at \"/content/drive/MyDrive/Seq2SeqModel/model\"\n",
            "\n",
            "Epoch 3 ends!!\n",
            "\n",
            "\n",
            "Epoch 4 begins:-\n",
            "\n",
            "Epoch 4/40, Batch 100/1562, Batch Loss: 1.4556\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 4/40, Batch 200/1562, Batch Loss: 1.8698\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 4/40, Batch 300/1562, Batch Loss: 1.5446\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 4/40, Batch 400/1562, Batch Loss: 1.7739\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 4/40, Batch 500/1562, Batch Loss: 1.6970\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 4/40, Batch 600/1562, Batch Loss: 1.8099\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 4/40, Batch 700/1562, Batch Loss: 1.5070\n",
            "Translated sentence: <SOS>please <EOS>\n",
            "\n",
            "Epoch 4/40, Batch 800/1562, Batch Loss: 1.6796\n",
            "Translated sentence: <SOS>please hurry <EOS>\n",
            "\n",
            "Epoch 4/40, Batch 900/1562, Batch Loss: 1.6957\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 4/40, Batch 1000/1562, Batch Loss: 1.6961\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 4/40, Batch 1100/1562, Batch Loss: 1.2367\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 4/40, Batch 1200/1562, Batch Loss: 1.3885\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 4/40, Batch 1300/1562, Batch Loss: 1.7012\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 4/40, Batch 1400/1562, Batch Loss: 1.5297\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 4/40, Batch 1500/1562, Batch Loss: 1.3558\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "\n",
            "Epoch 4/40, Epoch Loss: 1.6474\n",
            "Epoch Loss improved from 1.9421 to 1.6474\n",
            "Improved Model saved at \"/content/drive/MyDrive/Seq2SeqModel/model\"\n",
            "\n",
            "Epoch 4 ends!!\n",
            "\n",
            "\n",
            "Epoch 5 begins:-\n",
            "\n",
            "Epoch 5/40, Batch 100/1562, Batch Loss: 1.5054\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 5/40, Batch 200/1562, Batch Loss: 1.3438\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 5/40, Batch 300/1562, Batch Loss: 1.2744\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 5/40, Batch 400/1562, Batch Loss: 1.6464\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 5/40, Batch 500/1562, Batch Loss: 1.6783\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 5/40, Batch 600/1562, Batch Loss: 1.3595\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 5/40, Batch 700/1562, Batch Loss: 1.5377\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 5/40, Batch 800/1562, Batch Loss: 1.1532\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 5/40, Batch 900/1562, Batch Loss: 1.6174\n",
            "Translated sentence: <SOS>please hurry <EOS>\n",
            "\n",
            "Epoch 5/40, Batch 1000/1562, Batch Loss: 1.6709\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 5/40, Batch 1100/1562, Batch Loss: 1.6581\n",
            "Translated sentence: <SOS>please sit down seat <EOS>\n",
            "\n",
            "Epoch 5/40, Batch 1200/1562, Batch Loss: 1.5597\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 5/40, Batch 1300/1562, Batch Loss: 1.3651\n",
            "Translated sentence: <SOS>please sit down seat <EOS>\n",
            "\n",
            "Epoch 5/40, Batch 1400/1562, Batch Loss: 1.5203\n",
            "Translated sentence: <SOS>please sit down seat <EOS>\n",
            "\n",
            "Epoch 5/40, Batch 1500/1562, Batch Loss: 1.5877\n",
            "Translated sentence: <SOS>sit down seat belt <EOS>\n",
            "\n",
            "\n",
            "Epoch 5/40, Epoch Loss: 1.4463\n",
            "Epoch Loss improved from 1.6474 to 1.4463\n",
            "Improved Model saved at \"/content/drive/MyDrive/Seq2SeqModel/model\"\n",
            "\n",
            "Epoch 5 ends!!\n",
            "\n",
            "\n",
            "Epoch 6 begins:-\n",
            "\n",
            "Epoch 6/40, Batch 100/1562, Batch Loss: 1.7298\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 6/40, Batch 200/1562, Batch Loss: 1.1949\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 6/40, Batch 300/1562, Batch Loss: 1.0617\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 6/40, Batch 400/1562, Batch Loss: 1.1279\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 6/40, Batch 500/1562, Batch Loss: 1.1456\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 6/40, Batch 600/1562, Batch Loss: 1.2118\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 6/40, Batch 700/1562, Batch Loss: 1.6467\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 6/40, Batch 800/1562, Batch Loss: 1.0778\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 6/40, Batch 900/1562, Batch Loss: 1.3127\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 6/40, Batch 1000/1562, Batch Loss: 1.1792\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 6/40, Batch 1100/1562, Batch Loss: 1.0631\n",
            "Translated sentence: <SOS>sit sit seat <EOS>\n",
            "\n",
            "Epoch 6/40, Batch 1200/1562, Batch Loss: 1.5497\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 6/40, Batch 1300/1562, Batch Loss: 0.9907\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 6/40, Batch 1400/1562, Batch Loss: 1.2130\n",
            "Translated sentence: <SOS>please hurry <EOS>\n",
            "\n",
            "Epoch 6/40, Batch 1500/1562, Batch Loss: 1.4791\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "\n",
            "Epoch 6/40, Epoch Loss: 1.2860\n",
            "Epoch Loss improved from 1.4463 to 1.2860\n",
            "Improved Model saved at \"/content/drive/MyDrive/Seq2SeqModel/model\"\n",
            "\n",
            "Epoch 6 ends!!\n",
            "\n",
            "\n",
            "Epoch 7 begins:-\n",
            "\n",
            "Epoch 7/40, Batch 100/1562, Batch Loss: 0.8231\n",
            "Translated sentence: <SOS>please hurry <EOS>\n",
            "\n",
            "Epoch 7/40, Batch 200/1562, Batch Loss: 1.2581\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 7/40, Batch 300/1562, Batch Loss: 1.1070\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 7/40, Batch 400/1562, Batch Loss: 1.1415\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 7/40, Batch 500/1562, Batch Loss: 1.1497\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 7/40, Batch 600/1562, Batch Loss: 1.2641\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 7/40, Batch 700/1562, Batch Loss: 1.1754\n",
            "Translated sentence: <SOS>please sit <EOS>\n",
            "\n",
            "Epoch 7/40, Batch 800/1562, Batch Loss: 1.0569\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 7/40, Batch 900/1562, Batch Loss: 1.2094\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 7/40, Batch 1000/1562, Batch Loss: 1.8242\n",
            "Translated sentence: <SOS>please hurry seat <EOS>\n",
            "\n",
            "Epoch 7/40, Batch 1100/1562, Batch Loss: 0.9724\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 7/40, Batch 1200/1562, Batch Loss: 1.2690\n",
            "Translated sentence: <SOS>please take one <EOS>\n",
            "\n",
            "Epoch 7/40, Batch 1300/1562, Batch Loss: 0.9850\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 7/40, Batch 1400/1562, Batch Loss: 1.4243\n",
            "Translated sentence: <SOS>please sit down seat <EOS>\n",
            "\n",
            "Epoch 7/40, Batch 1500/1562, Batch Loss: 1.5616\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "\n",
            "Epoch 7/40, Epoch Loss: 1.1749\n",
            "Epoch Loss improved from 1.2860 to 1.1749\n",
            "Improved Model saved at \"/content/drive/MyDrive/Seq2SeqModel/model\"\n",
            "\n",
            "Epoch 7 ends!!\n",
            "\n",
            "\n",
            "Epoch 8 begins:-\n",
            "\n",
            "Epoch 8/40, Batch 100/1562, Batch Loss: 0.9562\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 8/40, Batch 200/1562, Batch Loss: 1.2014\n",
            "Translated sentence: <SOS>please sit seat <EOS>\n",
            "\n",
            "Epoch 8/40, Batch 300/1562, Batch Loss: 0.9539\n",
            "Translated sentence: <SOS>please hurry <EOS>\n",
            "\n",
            "Epoch 8/40, Batch 400/1562, Batch Loss: 1.0827\n",
            "Translated sentence: <SOS>please hurry <EOS>\n",
            "\n",
            "Epoch 8/40, Batch 500/1562, Batch Loss: 1.3249\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 8/40, Batch 600/1562, Batch Loss: 1.0617\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 8/40, Batch 700/1562, Batch Loss: 1.0822\n",
            "Translated sentence: <SOS>sit down <EOS>\n",
            "\n",
            "Epoch 8/40, Batch 800/1562, Batch Loss: 1.1930\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 8/40, Batch 900/1562, Batch Loss: 1.0212\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 8/40, Batch 1000/1562, Batch Loss: 1.3157\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 8/40, Batch 1100/1562, Batch Loss: 1.0613\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 8/40, Batch 1200/1562, Batch Loss: 1.0860\n",
            "Translated sentence: <SOS>sit down <EOS>\n",
            "\n",
            "Epoch 8/40, Batch 1300/1562, Batch Loss: 1.1181\n",
            "Translated sentence: <SOS>please take seat <EOS>\n",
            "\n",
            "Epoch 8/40, Batch 1400/1562, Batch Loss: 1.0527\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 8/40, Batch 1500/1562, Batch Loss: 1.4683\n",
            "Translated sentence: <SOS>please hurry <EOS>\n",
            "\n",
            "\n",
            "Epoch 8/40, Epoch Loss: 1.0875\n",
            "Epoch Loss improved from 1.1749 to 1.0875\n",
            "Improved Model saved at \"/content/drive/MyDrive/Seq2SeqModel/model\"\n",
            "\n",
            "Epoch 8 ends!!\n",
            "\n",
            "\n",
            "Epoch 9 begins:-\n",
            "\n",
            "Epoch 9/40, Batch 100/1562, Batch Loss: 0.9337\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 9/40, Batch 200/1562, Batch Loss: 0.6372\n",
            "Translated sentence: <SOS>please hurry <EOS>\n",
            "\n",
            "Epoch 9/40, Batch 300/1562, Batch Loss: 0.8706\n",
            "Translated sentence: <SOS>please sit down seat <EOS>\n",
            "\n",
            "Epoch 9/40, Batch 400/1562, Batch Loss: 1.1945\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 9/40, Batch 500/1562, Batch Loss: 0.8235\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 9/40, Batch 600/1562, Batch Loss: 1.1240\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 9/40, Batch 700/1562, Batch Loss: 0.9512\n",
            "Translated sentence: <SOS>please take a seat <EOS>\n",
            "\n",
            "Epoch 9/40, Batch 800/1562, Batch Loss: 0.8901\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 9/40, Batch 900/1562, Batch Loss: 0.9718\n",
            "Translated sentence: <SOS>please sit yourselves <EOS>\n",
            "\n",
            "Epoch 9/40, Batch 1000/1562, Batch Loss: 0.8498\n",
            "Translated sentence: <SOS>please hurry yourselves <EOS>\n",
            "\n",
            "Epoch 9/40, Batch 1100/1562, Batch Loss: 0.9424\n",
            "Translated sentence: <SOS>please take a seat <EOS>\n",
            "\n",
            "Epoch 9/40, Batch 1200/1562, Batch Loss: 0.7545\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 9/40, Batch 1300/1562, Batch Loss: 0.9278\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 9/40, Batch 1400/1562, Batch Loss: 1.1103\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 9/40, Batch 1500/1562, Batch Loss: 1.0492\n",
            "Translated sentence: <SOS>please sit seat <EOS>\n",
            "\n",
            "\n",
            "Epoch 9/40, Epoch Loss: 1.0089\n",
            "Epoch Loss improved from 1.0875 to 1.0089\n",
            "Improved Model saved at \"/content/drive/MyDrive/Seq2SeqModel/model\"\n",
            "\n",
            "Epoch 9 ends!!\n",
            "\n",
            "\n",
            "Epoch 10 begins:-\n",
            "\n",
            "Epoch 10/40, Batch 100/1562, Batch Loss: 1.1245\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 10/40, Batch 200/1562, Batch Loss: 0.9858\n",
            "Translated sentence: <SOS>sit down <EOS>\n",
            "\n",
            "Epoch 10/40, Batch 300/1562, Batch Loss: 0.9323\n",
            "Translated sentence: <SOS>please sit seat <EOS>\n",
            "\n",
            "Epoch 10/40, Batch 400/1562, Batch Loss: 0.8466\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 10/40, Batch 500/1562, Batch Loss: 0.8050\n",
            "Translated sentence: <SOS>please sit down seat <EOS>\n",
            "\n",
            "Epoch 10/40, Batch 600/1562, Batch Loss: 0.9238\n",
            "Translated sentence: <SOS>please sit <EOS>\n",
            "\n",
            "Epoch 10/40, Batch 700/1562, Batch Loss: 0.9241\n",
            "Translated sentence: <SOS>please take seat <EOS>\n",
            "\n",
            "Epoch 10/40, Batch 800/1562, Batch Loss: 1.0626\n",
            "Translated sentence: <SOS>please sit down seat <EOS>\n",
            "\n",
            "Epoch 10/40, Batch 900/1562, Batch Loss: 1.2671\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 10/40, Batch 1000/1562, Batch Loss: 0.9107\n",
            "Translated sentence: <SOS>please hurry <EOS>\n",
            "\n",
            "Epoch 10/40, Batch 1100/1562, Batch Loss: 1.0080\n",
            "Translated sentence: <SOS>sit down please <EOS>\n",
            "\n",
            "Epoch 10/40, Batch 1200/1562, Batch Loss: 0.9300\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 10/40, Batch 1300/1562, Batch Loss: 0.7206\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 10/40, Batch 1400/1562, Batch Loss: 0.8439\n",
            "Translated sentence: <SOS>please hurry <EOS>\n",
            "\n",
            "Epoch 10/40, Batch 1500/1562, Batch Loss: 1.0173\n",
            "Translated sentence: <SOS>please sit seat <EOS>\n",
            "\n",
            "\n",
            "Epoch 10/40, Epoch Loss: 0.9562\n",
            "Epoch Loss improved from 1.0089 to 0.9562\n",
            "Improved Model saved at \"/content/drive/MyDrive/Seq2SeqModel/model\"\n",
            "\n",
            "Epoch 10 ends!!\n",
            "\n",
            "\n",
            "Epoch 11 begins:-\n",
            "\n",
            "Epoch 11/40, Batch 100/1562, Batch Loss: 1.0380\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 11/40, Batch 200/1562, Batch Loss: 1.0512\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 11/40, Batch 300/1562, Batch Loss: 0.7478\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 11/40, Batch 400/1562, Batch Loss: 0.9144\n",
            "Translated sentence: <SOS>please sit down seat <EOS>\n",
            "\n",
            "Epoch 11/40, Batch 500/1562, Batch Loss: 1.0280\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 11/40, Batch 600/1562, Batch Loss: 0.7451\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 11/40, Batch 700/1562, Batch Loss: 0.8214\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 11/40, Batch 800/1562, Batch Loss: 1.0744\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 11/40, Batch 900/1562, Batch Loss: 0.9342\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 11/40, Batch 1000/1562, Batch Loss: 0.9008\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 11/40, Batch 1100/1562, Batch Loss: 0.9201\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 11/40, Batch 1200/1562, Batch Loss: 1.2023\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 11/40, Batch 1300/1562, Batch Loss: 1.0323\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 11/40, Batch 1400/1562, Batch Loss: 1.0359\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 11/40, Batch 1500/1562, Batch Loss: 1.0105\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "\n",
            "Epoch 11/40, Epoch Loss: 0.9062\n",
            "Epoch Loss improved from 0.9562 to 0.9062\n",
            "Improved Model saved at \"/content/drive/MyDrive/Seq2SeqModel/model\"\n",
            "\n",
            "Epoch 11 ends!!\n",
            "\n",
            "\n",
            "Epoch 12 begins:-\n",
            "\n",
            "Epoch 12/40, Batch 100/1562, Batch Loss: 0.7333\n",
            "Translated sentence: <SOS>please hurry up <EOS>\n",
            "\n",
            "Epoch 12/40, Batch 200/1562, Batch Loss: 0.8868\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 12/40, Batch 300/1562, Batch Loss: 0.8637\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 12/40, Batch 400/1562, Batch Loss: 0.6449\n",
            "Translated sentence: <SOS>please take off <EOS>\n",
            "\n",
            "Epoch 12/40, Batch 500/1562, Batch Loss: 0.8093\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 12/40, Batch 600/1562, Batch Loss: 0.7732\n",
            "Translated sentence: <SOS>please hurry <EOS>\n",
            "\n",
            "Epoch 12/40, Batch 700/1562, Batch Loss: 0.9749\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 12/40, Batch 800/1562, Batch Loss: 0.8340\n",
            "Translated sentence: <SOS>please take <EOS>\n",
            "\n",
            "Epoch 12/40, Batch 900/1562, Batch Loss: 0.6699\n",
            "Translated sentence: <SOS>please take off seat <EOS>\n",
            "\n",
            "Epoch 12/40, Batch 1000/1562, Batch Loss: 1.1666\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 12/40, Batch 1100/1562, Batch Loss: 0.8164\n",
            "Translated sentence: <SOS>please take it <EOS>\n",
            "\n",
            "Epoch 12/40, Batch 1200/1562, Batch Loss: 0.9670\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 12/40, Batch 1300/1562, Batch Loss: 0.7086\n",
            "Translated sentence: <SOS>please you <EOS>\n",
            "\n",
            "Epoch 12/40, Batch 1400/1562, Batch Loss: 0.8834\n",
            "Translated sentence: <SOS>please take care of hand <EOS>\n",
            "\n",
            "Epoch 12/40, Batch 1500/1562, Batch Loss: 0.7367\n",
            "Translated sentence: <SOS>please down <UNK> please <EOS>\n",
            "\n",
            "\n",
            "Epoch 12/40, Epoch Loss: 0.8529\n",
            "Epoch Loss improved from 0.9062 to 0.8529\n",
            "Improved Model saved at \"/content/drive/MyDrive/Seq2SeqModel/model\"\n",
            "\n",
            "Epoch 12 ends!!\n",
            "\n",
            "\n",
            "Epoch 13 begins:-\n",
            "\n",
            "Epoch 13/40, Batch 100/1562, Batch Loss: 0.7929\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 13/40, Batch 200/1562, Batch Loss: 0.7561\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 13/40, Batch 300/1562, Batch Loss: 0.6189\n",
            "Translated sentence: <SOS>please sit down please <EOS>\n",
            "\n",
            "Epoch 13/40, Batch 400/1562, Batch Loss: 0.9887\n",
            "Translated sentence: <SOS>please <UNK> please <EOS>\n",
            "\n",
            "Epoch 13/40, Batch 500/1562, Batch Loss: 0.8277\n",
            "Translated sentence: <SOS>please hurry <EOS>\n",
            "\n",
            "Epoch 13/40, Batch 600/1562, Batch Loss: 0.6858\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 13/40, Batch 700/1562, Batch Loss: 0.7522\n",
            "Translated sentence: <SOS>sit down <EOS>\n",
            "\n",
            "Epoch 13/40, Batch 800/1562, Batch Loss: 0.9308\n",
            "Translated sentence: <SOS>sit down <EOS>\n",
            "\n",
            "Epoch 13/40, Batch 900/1562, Batch Loss: 0.8976\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 13/40, Batch 1000/1562, Batch Loss: 0.9766\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 13/40, Batch 1100/1562, Batch Loss: 0.8040\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 13/40, Batch 1200/1562, Batch Loss: 0.8149\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 13/40, Batch 1300/1562, Batch Loss: 0.8539\n",
            "Translated sentence: <SOS>sit down <EOS>\n",
            "\n",
            "Epoch 13/40, Batch 1400/1562, Batch Loss: 0.8183\n",
            "Translated sentence: <SOS>please sit <EOS>\n",
            "\n",
            "Epoch 13/40, Batch 1500/1562, Batch Loss: 0.7075\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "\n",
            "Epoch 13/40, Epoch Loss: 0.8222\n",
            "Epoch Loss improved from 0.8529 to 0.8222\n",
            "Improved Model saved at \"/content/drive/MyDrive/Seq2SeqModel/model\"\n",
            "\n",
            "Epoch 13 ends!!\n",
            "\n",
            "\n",
            "Epoch 14 begins:-\n",
            "\n",
            "Epoch 14/40, Batch 100/1562, Batch Loss: 1.1100\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 14/40, Batch 200/1562, Batch Loss: 0.6126\n",
            "Translated sentence: <SOS>sit down <EOS>\n",
            "\n",
            "Epoch 14/40, Batch 300/1562, Batch Loss: 0.7707\n",
            "Translated sentence: <SOS>please hurry <EOS>\n",
            "\n",
            "Epoch 14/40, Batch 400/1562, Batch Loss: 0.7528\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 14/40, Batch 500/1562, Batch Loss: 0.8122\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 14/40, Batch 600/1562, Batch Loss: 0.6081\n",
            "Translated sentence: <SOS>sit down <EOS>\n",
            "\n",
            "Epoch 14/40, Batch 700/1562, Batch Loss: 0.9043\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 14/40, Batch 800/1562, Batch Loss: 0.8023\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 14/40, Batch 900/1562, Batch Loss: 0.6907\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 14/40, Batch 1000/1562, Batch Loss: 0.6166\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 14/40, Batch 1100/1562, Batch Loss: 0.7318\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 14/40, Batch 1200/1562, Batch Loss: 0.7137\n",
            "Translated sentence: <SOS>sit down <EOS>\n",
            "\n",
            "Epoch 14/40, Batch 1300/1562, Batch Loss: 0.9687\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 14/40, Batch 1400/1562, Batch Loss: 1.2952\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 14/40, Batch 1500/1562, Batch Loss: 0.7782\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "\n",
            "Epoch 14/40, Epoch Loss: 0.7849\n",
            "Epoch Loss improved from 0.8222 to 0.7849\n",
            "Improved Model saved at \"/content/drive/MyDrive/Seq2SeqModel/model\"\n",
            "\n",
            "Epoch 14 ends!!\n",
            "\n",
            "\n",
            "Epoch 15 begins:-\n",
            "\n",
            "Epoch 15/40, Batch 100/1562, Batch Loss: 1.1859\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 15/40, Batch 200/1562, Batch Loss: 0.8208\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 15/40, Batch 300/1562, Batch Loss: 0.6906\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 15/40, Batch 400/1562, Batch Loss: 0.5271\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 15/40, Batch 500/1562, Batch Loss: 0.9235\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 15/40, Batch 600/1562, Batch Loss: 0.8752\n",
            "Translated sentence: <SOS>please down <EOS>\n",
            "\n",
            "Epoch 15/40, Batch 700/1562, Batch Loss: 0.7712\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 15/40, Batch 800/1562, Batch Loss: 0.7959\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 15/40, Batch 900/1562, Batch Loss: 0.7419\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 15/40, Batch 1000/1562, Batch Loss: 0.6074\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 15/40, Batch 1100/1562, Batch Loss: 0.7440\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 15/40, Batch 1200/1562, Batch Loss: 0.6799\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 15/40, Batch 1300/1562, Batch Loss: 0.6267\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 15/40, Batch 1400/1562, Batch Loss: 0.6976\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n",
            "Epoch 15/40, Batch 1500/1562, Batch Loss: 0.6898\n",
            "Translated sentence: <SOS>sit down seat <EOS>\n",
            "\n",
            "\n",
            "Epoch 15/40, Epoch Loss: 0.7643\n",
            "Epoch Loss improved from 0.7849 to 0.7643\n",
            "Improved Model saved at \"/content/drive/MyDrive/Seq2SeqModel/model\"\n",
            "\n",
            "Epoch 15 ends!!\n",
            "\n",
            "\n",
            "Epoch 16 begins:-\n",
            "\n",
            "Epoch 16/40, Batch 100/1562, Batch Loss: 0.7146\n",
            "Translated sentence: <SOS>please sit down <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Testing Arena"
      ],
      "metadata": {
        "id": "UyV7LITzOE3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Vocab size of source is: {len(dataset.vocab.itos_source)} and that of target is: {len(dataset.vocab.itos_target)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zhl8YQi-SyIF",
        "outputId": "8a81be3f-a1e8-4682-8182-2fbde189ee0f"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size of source is: 9918 and that of target is: 6525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_chk_samples=100\n",
        "idx=0\n",
        "for sample in range(1,num_chk_samples+1):\n",
        "  #idx=random.randint(0,num_samples)\n",
        "  print(f'Sample no. {sample}, Dataset Index {idx}:-')\n",
        "  source,target=dataset[idx]\n",
        "  idx+=1\n",
        "  validation_sentence_source=''\n",
        "  for word_idx in source:\n",
        "    validation_sentence_source+=dataset.vocab.itos_source[word_idx.item()]+' '\n",
        "  validation_sentence_source=validation_sentence_source[:-1]\n",
        "  validation_sentence_target=''\n",
        "  validation_sentence_output=model.translate(source,dataset.vocab.itos_target,device)\n",
        "  for word in target:\n",
        "    validation_sentence_target+=dataset.vocab.itos_target[word.item()]+' '\n",
        "  validation_sentence_target=validation_sentence_target[:-1]\n",
        "\n",
        "  print(f'Source Sentence: {validation_sentence_source}')\n",
        "  print(f'Target Sentence: {validation_sentence_target}')\n",
        "  print(f'Translated Sentence: {validation_sentence_output}\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf91gFs0pa4Z",
        "outputId": "1fa77f9d-91f0-4759-d56a-49810c61a659"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample no. 1, Dataset Index 0:-\n",
            "Source Sentence: <SOS> hallo <EOS>\n",
            "Target Sentence: <SOS> hi <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 2, Dataset Index 1:-\n",
            "Source Sentence: <SOS> grüß gott <EOS>\n",
            "Target Sentence: <SOS> hi <EOS>\n",
            "Translated Sentence: <SOS> is some <EOS>\n",
            "\n",
            "\n",
            "Sample no. 3, Dataset Index 2:-\n",
            "Source Sentence: <SOS> lauf <EOS>\n",
            "Target Sentence: <SOS> run <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 4, Dataset Index 3:-\n",
            "Source Sentence: <SOS> potzdonner <EOS>\n",
            "Target Sentence: <SOS> wow <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 5, Dataset Index 4:-\n",
            "Source Sentence: <SOS> <UNK> <EOS>\n",
            "Target Sentence: <SOS> wow <EOS>\n",
            "Translated Sentence: <SOS> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 6, Dataset Index 5:-\n",
            "Source Sentence: <SOS> feuer <EOS>\n",
            "Target Sentence: <SOS> fire <EOS>\n",
            "Translated Sentence: <SOS> fire <EOS>\n",
            "\n",
            "\n",
            "Sample no. 7, Dataset Index 6:-\n",
            "Source Sentence: <SOS> hilfe <EOS>\n",
            "Target Sentence: <SOS> help <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 8, Dataset Index 7:-\n",
            "Source Sentence: <SOS> zu <UNK> <EOS>\n",
            "Target Sentence: <SOS> help <EOS>\n",
            "Translated Sentence: <SOS> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 9, Dataset Index 8:-\n",
            "Source Sentence: <SOS> stopp <EOS>\n",
            "Target Sentence: <SOS> stop <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 10, Dataset Index 9:-\n",
            "Source Sentence: <SOS> warte <EOS>\n",
            "Target Sentence: <SOS> wait <EOS>\n",
            "Translated Sentence: <SOS> wait <EOS>\n",
            "\n",
            "\n",
            "Sample no. 11, Dataset Index 10:-\n",
            "Source Sentence: <SOS> mach weiter <EOS>\n",
            "Target Sentence: <SOS> go on <EOS>\n",
            "Translated Sentence: <SOS> go on <EOS>\n",
            "\n",
            "\n",
            "Sample no. 12, Dataset Index 11:-\n",
            "Source Sentence: <SOS> hallo <EOS>\n",
            "Target Sentence: <SOS> hello <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 13, Dataset Index 12:-\n",
            "Source Sentence: <SOS> ich rannte <EOS>\n",
            "Target Sentence: <SOS> i ran <EOS>\n",
            "Translated Sentence: <SOS> ran <EOS>\n",
            "\n",
            "\n",
            "Sample no. 14, Dataset Index 13:-\n",
            "Source Sentence: <SOS> ich verstehe <EOS>\n",
            "Target Sentence: <SOS> i see <EOS>\n",
            "Translated Sentence: <SOS> i understand <EOS>\n",
            "\n",
            "\n",
            "Sample no. 15, Dataset Index 14:-\n",
            "Source Sentence: <SOS> <UNK> <EOS>\n",
            "Target Sentence: <SOS> i see <EOS>\n",
            "Translated Sentence: <SOS> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 16, Dataset Index 15:-\n",
            "Source Sentence: <SOS> ich probiere es <EOS>\n",
            "Target Sentence: <SOS> i try <EOS>\n",
            "Translated Sentence: <SOS> i 'll check <EOS>\n",
            "\n",
            "\n",
            "Sample no. 17, Dataset Index 16:-\n",
            "Source Sentence: <SOS> ich hab gewonnen <EOS>\n",
            "Target Sentence: <SOS> i won <EOS>\n",
            "Translated Sentence: <SOS> i won <EOS>\n",
            "\n",
            "\n",
            "Sample no. 18, Dataset Index 17:-\n",
            "Source Sentence: <SOS> ich habe gewonnen <EOS>\n",
            "Target Sentence: <SOS> i won <EOS>\n",
            "Translated Sentence: <SOS> it won <EOS>\n",
            "\n",
            "\n",
            "Sample no. 19, Dataset Index 18:-\n",
            "Source Sentence: <SOS> lächeln <EOS>\n",
            "Target Sentence: <SOS> smile <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 20, Dataset Index 19:-\n",
            "Source Sentence: <SOS> zum wohl <EOS>\n",
            "Target Sentence: <SOS> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> to try <EOS>\n",
            "\n",
            "\n",
            "Sample no. 21, Dataset Index 20:-\n",
            "Source Sentence: <SOS> keine bewegung <EOS>\n",
            "Target Sentence: <SOS> freeze <EOS>\n",
            "Translated Sentence: <SOS> do n't change <EOS>\n",
            "\n",
            "\n",
            "Sample no. 22, Dataset Index 21:-\n",
            "Source Sentence: <SOS> stehenbleiben <EOS>\n",
            "Target Sentence: <SOS> freeze <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 23, Dataset Index 22:-\n",
            "Source Sentence: <SOS> kapiert <EOS>\n",
            "Target Sentence: <SOS> got it <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 24, Dataset Index 23:-\n",
            "Source Sentence: <SOS> verstanden <EOS>\n",
            "Target Sentence: <SOS> got it <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 25, Dataset Index 24:-\n",
            "Source Sentence: <SOS> einverstanden <EOS>\n",
            "Target Sentence: <SOS> got it <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 26, Dataset Index 25:-\n",
            "Source Sentence: <SOS> er rannte <EOS>\n",
            "Target Sentence: <SOS> he ran <EOS>\n",
            "Translated Sentence: <SOS> he ran <EOS>\n",
            "\n",
            "\n",
            "Sample no. 27, Dataset Index 26:-\n",
            "Source Sentence: <SOS> er lief <EOS>\n",
            "Target Sentence: <SOS> he ran <EOS>\n",
            "Translated Sentence: <SOS> he ran away <EOS>\n",
            "\n",
            "\n",
            "Sample no. 28, Dataset Index 27:-\n",
            "Source Sentence: <SOS> mach mit <EOS>\n",
            "Target Sentence: <SOS> <UNK> in <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 29, Dataset Index 28:-\n",
            "Source Sentence: <SOS> drück mich <EOS>\n",
            "Target Sentence: <SOS> hug me <EOS>\n",
            "Translated Sentence: <SOS> help me <EOS>\n",
            "\n",
            "\n",
            "Sample no. 30, Dataset Index 29:-\n",
            "Source Sentence: <SOS> nimm mich in den arm <EOS>\n",
            "Target Sentence: <SOS> hug me <EOS>\n",
            "Translated Sentence: <SOS> take me to hug <EOS>\n",
            "\n",
            "\n",
            "Sample no. 31, Dataset Index 30:-\n",
            "Source Sentence: <SOS> umarme mich <EOS>\n",
            "Target Sentence: <SOS> hug me <EOS>\n",
            "Translated Sentence: <SOS> for me <EOS>\n",
            "\n",
            "\n",
            "Sample no. 32, Dataset Index 31:-\n",
            "Source Sentence: <SOS> ich fiel <EOS>\n",
            "Target Sentence: <SOS> i fell <EOS>\n",
            "Translated Sentence: <SOS> i fell <EOS>\n",
            "\n",
            "\n",
            "Sample no. 33, Dataset Index 32:-\n",
            "Source Sentence: <SOS> ich fiel hin <EOS>\n",
            "Target Sentence: <SOS> i fell <EOS>\n",
            "Translated Sentence: <SOS> was accepted <EOS>\n",
            "\n",
            "\n",
            "Sample no. 34, Dataset Index 33:-\n",
            "Source Sentence: <SOS> ich stürzte <EOS>\n",
            "Target Sentence: <SOS> i fell <EOS>\n",
            "Translated Sentence: <SOS> i walked <EOS>\n",
            "\n",
            "\n",
            "Sample no. 35, Dataset Index 34:-\n",
            "Source Sentence: <SOS> ich bin hingefallen <EOS>\n",
            "Target Sentence: <SOS> i fell <EOS>\n",
            "Translated Sentence: <SOS> i 'm <EOS>\n",
            "\n",
            "\n",
            "Sample no. 36, Dataset Index 35:-\n",
            "Source Sentence: <SOS> ich bin gestürzt <EOS>\n",
            "Target Sentence: <SOS> i fell <EOS>\n",
            "Translated Sentence: <SOS> i fell <EOS>\n",
            "\n",
            "\n",
            "Sample no. 37, Dataset Index 36:-\n",
            "Source Sentence: <SOS> ich weiß <EOS>\n",
            "Target Sentence: <SOS> i know <EOS>\n",
            "Translated Sentence: <SOS> i <EOS>\n",
            "\n",
            "\n",
            "Sample no. 38, Dataset Index 37:-\n",
            "Source Sentence: <SOS> ich habe gelogen <EOS>\n",
            "Target Sentence: <SOS> i lied <EOS>\n",
            "Translated Sentence: <SOS> i was <EOS>\n",
            "\n",
            "\n",
            "Sample no. 39, Dataset Index 38:-\n",
            "Source Sentence: <SOS> ich habe verloren <EOS>\n",
            "Target Sentence: <SOS> i lost <EOS>\n",
            "Translated Sentence: <SOS> i lost my mind <EOS>\n",
            "\n",
            "\n",
            "Sample no. 40, Dataset Index 39:-\n",
            "Source Sentence: <SOS> ich habe bezahlt <EOS>\n",
            "Target Sentence: <SOS> i paid <EOS>\n",
            "Translated Sentence: <SOS> it paid <EOS>\n",
            "\n",
            "\n",
            "Sample no. 41, Dataset Index 40:-\n",
            "Source Sentence: <SOS> ich zahlte <EOS>\n",
            "Target Sentence: <SOS> i paid <EOS>\n",
            "Translated Sentence: <SOS> help <EOS>\n",
            "\n",
            "\n",
            "Sample no. 42, Dataset Index 41:-\n",
            "Source Sentence: <SOS> ich sang <EOS>\n",
            "Target Sentence: <SOS> i sang <EOS>\n",
            "Translated Sentence: <SOS> i sang <EOS>\n",
            "\n",
            "\n",
            "Sample no. 43, Dataset Index 42:-\n",
            "Source Sentence: <SOS> ich schwimme <EOS>\n",
            "Target Sentence: <SOS> i swim <EOS>\n",
            "Translated Sentence: <SOS> i swim <EOS>\n",
            "\n",
            "\n",
            "Sample no. 44, Dataset Index 43:-\n",
            "Source Sentence: <SOS> ich bin 19 jahre alt <EOS>\n",
            "Target Sentence: <SOS> i 'm 19 <EOS>\n",
            "Translated Sentence: <SOS> i 'm 19 years old <EOS>\n",
            "\n",
            "\n",
            "Sample no. 45, Dataset Index 44:-\n",
            "Source Sentence: <SOS> ich bin 19 <EOS>\n",
            "Target Sentence: <SOS> i 'm 19 <EOS>\n",
            "Translated Sentence: <SOS> i 'm 19 <EOS>\n",
            "\n",
            "\n",
            "Sample no. 46, Dataset Index 45:-\n",
            "Source Sentence: <SOS> mir geht's gut <EOS>\n",
            "Target Sentence: <SOS> i 'm ok <EOS>\n",
            "Translated Sentence: <SOS> i 'm fine <EOS>\n",
            "\n",
            "\n",
            "Sample no. 47, Dataset Index 46:-\n",
            "Source Sentence: <SOS> es geht mir gut <EOS>\n",
            "Target Sentence: <SOS> i 'm ok <EOS>\n",
            "Translated Sentence: <SOS> i 'm fine <EOS>\n",
            "\n",
            "\n",
            "Sample no. 48, Dataset Index 47:-\n",
            "Source Sentence: <SOS> ich bin wach <EOS>\n",
            "Target Sentence: <SOS> i 'm up <EOS>\n",
            "Translated Sentence: <SOS> i awake awake <EOS>\n",
            "\n",
            "\n",
            "Sample no. 49, Dataset Index 48:-\n",
            "Source Sentence: <SOS> ich bin auf <EOS>\n",
            "Target Sentence: <SOS> i 'm up <EOS>\n",
            "Translated Sentence: <SOS> i 'm up <EOS>\n",
            "\n",
            "\n",
            "Sample no. 50, Dataset Index 49:-\n",
            "Source Sentence: <SOS> unmöglich <EOS>\n",
            "Target Sentence: <SOS> no way <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 51, Dataset Index 50:-\n",
            "Source Sentence: <SOS> das kommt nicht in frage <EOS>\n",
            "Target Sentence: <SOS> no way <EOS>\n",
            "Translated Sentence: <SOS> that is n't coming <EOS>\n",
            "\n",
            "\n",
            "Sample no. 52, Dataset Index 51:-\n",
            "Source Sentence: <SOS> das gibt ’s doch nicht <EOS>\n",
            "Target Sentence: <SOS> no way <EOS>\n",
            "Translated Sentence: <SOS> the <UNK> not any true <EOS>\n",
            "\n",
            "\n",
            "Sample no. 53, Dataset Index 52:-\n",
            "Source Sentence: <SOS> ausgeschlossen <EOS>\n",
            "Target Sentence: <SOS> no way <EOS>\n",
            "Translated Sentence: <SOS> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 54, Dataset Index 53:-\n",
            "Source Sentence: <SOS> in <UNK> weise <EOS>\n",
            "Target Sentence: <SOS> no way <EOS>\n",
            "Translated Sentence: <SOS> <UNK> eat in <EOS>\n",
            "\n",
            "\n",
            "Sample no. 55, Dataset Index 54:-\n",
            "Source Sentence: <SOS> wirklich <EOS>\n",
            "Target Sentence: <SOS> really <EOS>\n",
            "Translated Sentence: <SOS> really <EOS>\n",
            "\n",
            "\n",
            "Sample no. 56, Dataset Index 55:-\n",
            "Source Sentence: <SOS> echt <EOS>\n",
            "Target Sentence: <SOS> really <EOS>\n",
            "Translated Sentence: <SOS> really <EOS>\n",
            "\n",
            "\n",
            "Sample no. 57, Dataset Index 56:-\n",
            "Source Sentence: <SOS> im ernst <EOS>\n",
            "Target Sentence: <SOS> really <EOS>\n",
            "Translated Sentence: <SOS> seriously <EOS>\n",
            "\n",
            "\n",
            "Sample no. 58, Dataset Index 57:-\n",
            "Source Sentence: <SOS> danke <EOS>\n",
            "Target Sentence: <SOS> thanks <EOS>\n",
            "Translated Sentence: <SOS> thanks <EOS>\n",
            "\n",
            "\n",
            "Sample no. 59, Dataset Index 58:-\n",
            "Source Sentence: <SOS> versuch ’s <EOS>\n",
            "Target Sentence: <SOS> try it <EOS>\n",
            "Translated Sentence: <SOS> do it <EOS>\n",
            "\n",
            "\n",
            "Sample no. 60, Dataset Index 59:-\n",
            "Source Sentence: <SOS> wir haben gewonnen <EOS>\n",
            "Target Sentence: <SOS> we won <EOS>\n",
            "Translated Sentence: <SOS> we won <EOS>\n",
            "\n",
            "\n",
            "Sample no. 61, Dataset Index 60:-\n",
            "Source Sentence: <SOS> warum ich <EOS>\n",
            "Target Sentence: <SOS> why me <EOS>\n",
            "Translated Sentence: <SOS> i i why <EOS>\n",
            "\n",
            "\n",
            "Sample no. 62, Dataset Index 61:-\n",
            "Source Sentence: <SOS> frag tom <EOS>\n",
            "Target Sentence: <SOS> ask tom <EOS>\n",
            "Translated Sentence: <SOS> ask tom <EOS>\n",
            "\n",
            "\n",
            "Sample no. 63, Dataset Index 62:-\n",
            "Source Sentence: <SOS> fragen sie tom <EOS>\n",
            "Target Sentence: <SOS> ask tom <EOS>\n",
            "Translated Sentence: <SOS> ask tom <EOS>\n",
            "\n",
            "\n",
            "Sample no. 64, Dataset Index 63:-\n",
            "Source Sentence: <SOS> fragt tom <EOS>\n",
            "Target Sentence: <SOS> ask tom <EOS>\n",
            "Translated Sentence: <SOS> tom tom <EOS>\n",
            "\n",
            "\n",
            "Sample no. 65, Dataset Index 64:-\n",
            "Source Sentence: <SOS> fantastisch <EOS>\n",
            "Target Sentence: <SOS> awesome <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 66, Dataset Index 65:-\n",
            "Source Sentence: <SOS> entspann dich <EOS>\n",
            "Target Sentence: <SOS> be cool <EOS>\n",
            "Translated Sentence: <SOS> catch a decision <EOS>\n",
            "\n",
            "\n",
            "Sample no. 67, Dataset Index 66:-\n",
            "Source Sentence: <SOS> sei nicht ungerecht <EOS>\n",
            "Target Sentence: <SOS> be fair <EOS>\n",
            "Translated Sentence: <SOS> do n't be used <EOS>\n",
            "\n",
            "\n",
            "Sample no. 68, Dataset Index 67:-\n",
            "Source Sentence: <SOS> sei fair <EOS>\n",
            "Target Sentence: <SOS> be fair <EOS>\n",
            "Translated Sentence: <SOS> be fair <EOS>\n",
            "\n",
            "\n",
            "Sample no. 69, Dataset Index 68:-\n",
            "Source Sentence: <SOS> sei nett <EOS>\n",
            "Target Sentence: <SOS> be nice <EOS>\n",
            "Translated Sentence: <SOS> be nice nice boy <EOS>\n",
            "\n",
            "\n",
            "Sample no. 70, Dataset Index 69:-\n",
            "Source Sentence: <SOS> seien sie nett <EOS>\n",
            "Target Sentence: <SOS> be nice <EOS>\n",
            "Translated Sentence: <SOS> be nice <EOS>\n",
            "\n",
            "\n",
            "Sample no. 71, Dataset Index 70:-\n",
            "Source Sentence: <SOS> geh weg <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> go away <EOS>\n",
            "\n",
            "\n",
            "Sample no. 72, Dataset Index 71:-\n",
            "Source Sentence: <SOS> hau ab <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 73, Dataset Index 72:-\n",
            "Source Sentence: <SOS> verschwinde <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 74, Dataset Index 73:-\n",
            "Source Sentence: <SOS> verdufte <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 75, Dataset Index 74:-\n",
            "Source Sentence: <SOS> mach dich fort <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> go away <EOS>\n",
            "\n",
            "\n",
            "Sample no. 76, Dataset Index 75:-\n",
            "Source Sentence: <SOS> zieh leine <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> is your <EOS>\n",
            "\n",
            "\n",
            "Sample no. 77, Dataset Index 76:-\n",
            "Source Sentence: <SOS> mach dich vom acker <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> make people <EOS>\n",
            "\n",
            "\n",
            "Sample no. 78, Dataset Index 77:-\n",
            "Source Sentence: <SOS> verzieh dich <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 79, Dataset Index 78:-\n",
            "Source Sentence: <SOS> verkrümele dich <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> go away <EOS>\n",
            "\n",
            "\n",
            "Sample no. 80, Dataset Index 79:-\n",
            "Source Sentence: <SOS> troll dich <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> move <EOS>\n",
            "\n",
            "\n",
            "Sample no. 81, Dataset Index 80:-\n",
            "Source Sentence: <SOS> zisch ab <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> get away <EOS>\n",
            "\n",
            "\n",
            "Sample no. 82, Dataset Index 81:-\n",
            "Source Sentence: <SOS> pack dich <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> take <EOS>\n",
            "\n",
            "\n",
            "Sample no. 83, Dataset Index 82:-\n",
            "Source Sentence: <SOS> mach ’ne fliege <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> go away <EOS>\n",
            "\n",
            "\n",
            "Sample no. 84, Dataset Index 83:-\n",
            "Source Sentence: <SOS> schwirr ab <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> get lost <EOS>\n",
            "\n",
            "\n",
            "Sample no. 85, Dataset Index 84:-\n",
            "Source Sentence: <SOS> mach die sause <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> get the facts <EOS>\n",
            "\n",
            "\n",
            "Sample no. 86, Dataset Index 85:-\n",
            "Source Sentence: <SOS> scher dich weg <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> go away <EOS>\n",
            "\n",
            "\n",
            "Sample no. 87, Dataset Index 86:-\n",
            "Source Sentence: <SOS> scher dich fort <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> say goodbye <EOS>\n",
            "\n",
            "\n",
            "Sample no. 88, Dataset Index 87:-\n",
            "Source Sentence: <SOS> ruf mich an <EOS>\n",
            "Target Sentence: <SOS> call me <EOS>\n",
            "Translated Sentence: <SOS> call me <EOS>\n",
            "\n",
            "\n",
            "Sample no. 89, Dataset Index 88:-\n",
            "Source Sentence: <SOS> komm herein <EOS>\n",
            "Target Sentence: <SOS> come in <EOS>\n",
            "Translated Sentence: <SOS> come in <EOS>\n",
            "\n",
            "\n",
            "Sample no. 90, Dataset Index 89:-\n",
            "Source Sentence: <SOS> herein <EOS>\n",
            "Target Sentence: <SOS> come in <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 91, Dataset Index 90:-\n",
            "Source Sentence: <SOS> komm <EOS>\n",
            "Target Sentence: <SOS> come on <EOS>\n",
            "Translated Sentence: <SOS> come <EOS>\n",
            "\n",
            "\n",
            "Sample no. 92, Dataset Index 91:-\n",
            "Source Sentence: <SOS> kommt <EOS>\n",
            "Target Sentence: <SOS> come on <EOS>\n",
            "Translated Sentence: <SOS> come <EOS>\n",
            "\n",
            "\n",
            "Sample no. 93, Dataset Index 92:-\n",
            "Source Sentence: <SOS> mach schon <EOS>\n",
            "Target Sentence: <SOS> come on <EOS>\n",
            "Translated Sentence: <SOS> come on <EOS>\n",
            "\n",
            "\n",
            "Sample no. 94, Dataset Index 93:-\n",
            "Source Sentence: <SOS> macht schon <EOS>\n",
            "Target Sentence: <SOS> come on <EOS>\n",
            "Translated Sentence: <SOS> try <EOS>\n",
            "\n",
            "\n",
            "Sample no. 95, Dataset Index 94:-\n",
            "Source Sentence: <SOS> komm schon <EOS>\n",
            "Target Sentence: <SOS> come on <EOS>\n",
            "Translated Sentence: <SOS> come on <EOS>\n",
            "\n",
            "\n",
            "Sample no. 96, Dataset Index 95:-\n",
            "Source Sentence: <SOS> hol tom <EOS>\n",
            "Target Sentence: <SOS> get tom <EOS>\n",
            "Translated Sentence: <SOS> get out <EOS>\n",
            "\n",
            "\n",
            "Sample no. 97, Dataset Index 96:-\n",
            "Source Sentence: <SOS> raus <EOS>\n",
            "Target Sentence: <SOS> get out <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 98, Dataset Index 97:-\n",
            "Source Sentence: <SOS> geht raus <EOS>\n",
            "Target Sentence: <SOS> get out <EOS>\n",
            "Translated Sentence: <SOS> get out <EOS>\n",
            "\n",
            "\n",
            "Sample no. 99, Dataset Index 98:-\n",
            "Source Sentence: <SOS> geh raus <EOS>\n",
            "Target Sentence: <SOS> get out <EOS>\n",
            "Translated Sentence: <SOS> go out <EOS>\n",
            "\n",
            "\n",
            "Sample no. 100, Dataset Index 99:-\n",
            "Source Sentence: <SOS> geht raus <EOS>\n",
            "Target Sentence: <SOS> get out <EOS>\n",
            "Translated Sentence: <SOS> get out <EOS>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot([i for i in range(1,len(epoch_losses)+1)],epoch_losses)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs Epochs')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VYwUnmzJulSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_inp='Wie geht es dir'\n",
        "source_word_idxs=[dataset.vocab.stoi_source['<SOS>'],]\n",
        "for word in [tok.text.lower() for tok in spacy_ger.tokenizer(source_inp)]:\n",
        "  source_word_idxs.append(dataset.vocab.stoi_source[word])\n",
        "source_word_idxs.append(dataset.vocab.stoi_source['<EOS>'])\n",
        "source_word_idxs=torch.tensor(source_word_idxs)\n",
        "\n",
        "translated_sentence=model.translate(source_word_idxs,dataset.vocab.itos_target,device)\n",
        "\n",
        "target_sentence='<SOS> '+'how do you do'+' <EOS>'\n",
        "print(f'Target sentence: {target_sentence}')\n",
        "print(f'Translated sentence: {translated_sentence}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSdjaYfwYGQI",
        "outputId": "7a0f1445-a55c-4994-be42-082c87def76f"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target sentence: <SOS> how do you do <EOS>\n",
            "Translated sentence: <SOS> how are you <EOS>\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9WLXCdb3_pMQ",
        "Tbk3wodxN2XJ"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNntp8KnyFoZm4BXLqIYxx2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}