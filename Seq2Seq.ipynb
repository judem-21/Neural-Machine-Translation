{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/judem-21/Seq2Seq-Model/blob/main/Seq2Seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1PolMPZOEbE"
      },
      "source": [
        "#Seq2Seq Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF7XsLNXhz7V"
      },
      "source": [
        "###Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "me-hNcwXhajQ"
      },
      "outputs": [],
      "source": [
        "import torch,torchvision\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms as transforms\n",
        "#from torch.torchmetrics.text.bleu import BLEUScore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QrDUgehUhzUU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from skimage import io\n",
        "import spacy\n",
        "from PIL import Image\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en\n",
        "!python -m spacy download de_core_news_sm\n",
        "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
        "spacy_ger = spacy.load(\"de_core_news_sm\")"
      ],
      "metadata": {
        "id": "5V6nyChz-yl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbkXCOiHiKAk"
      },
      "source": [
        "###Dataset (Loading and Testing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNytP7BRN1QL"
      },
      "source": [
        "####Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAJmpQHviJOU",
        "outputId": "69070ea2-e85c-4ff4-f0b9-82cba2802e66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2ScqFknWkYHX"
      },
      "outputs": [],
      "source": [
        "class Vocabulary:\n",
        "    def __init__(self, freq_threshold=3):\n",
        "        self.itos_source = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
        "        self.stoi_source = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
        "\n",
        "        self.itos_target = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
        "        self.stoi_target = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
        "\n",
        "        self.punctuation_marks = [\n",
        "    '.', ',', ';', ':', '!', '?', '-', '—', '(', ')', '[', ']', '{', '}',\n",
        "    \"'\", '\"', '...', '“', '”', '‘', '’', '/', '\\\\', '|', '@', '#', '$', '%',\n",
        "    '^', '&', '*', '_', '=', '+', '<', '>', '`', '~'\n",
        "]\n",
        "\n",
        "        self.freq_threshold = freq_threshold\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.itos)\n",
        "\n",
        "    @staticmethod\n",
        "    def tokenizer(text,key):\n",
        "      if key=='en':\n",
        "        return [tok.text.lower() for tok in spacy_eng.tokenizer(text)]\n",
        "      else:\n",
        "        return [tok.text.lower() for tok in spacy_ger.tokenizer(text)]\n",
        "\n",
        "    def build_vocabulary(self, sentence_list, key):\n",
        "        frequencies = {}\n",
        "        idx = 4\n",
        "\n",
        "        for sentence in sentence_list:\n",
        "          if key=='source': lookup=self.tokenizer(sentence,'de')\n",
        "          else: lookup=self.tokenizer(sentence,'en')\n",
        "\n",
        "          for word in lookup:\n",
        "            if word=='\\n' or word in self.punctuation_marks: continue\n",
        "\n",
        "            if word not in frequencies:\n",
        "              frequencies[word] = 1\n",
        "\n",
        "            else:\n",
        "              frequencies[word] += 1\n",
        "\n",
        "            if frequencies[word] == self.freq_threshold:\n",
        "              if key=='source':\n",
        "                self.stoi_source[word] = idx\n",
        "                self.itos_source[idx] = word\n",
        "              elif key=='target':\n",
        "                self.stoi_target[word] = idx\n",
        "                self.itos_target[idx] = word\n",
        "              idx += 1\n",
        "\n",
        "    def numericalize(self, text,key):\n",
        "        if key=='source':\n",
        "          tokenized_text = self.tokenizer(text,'de')\n",
        "          return [self.stoi_source[token] if token in self.stoi_source else self.stoi_source[\"<UNK>\"] for token in tokenized_text]\n",
        "        elif key=='target':\n",
        "          tokenized_text = self.tokenizer(text,'en')\n",
        "          return [self.stoi_target[token] if token in self.stoi_target else self.stoi_target[\"<UNK>\"] for token in tokenized_text]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class seq2seq_dataset(Dataset):\n",
        "    def __init__(self,dataset_path, num_samples=29000, freq_threshold=3):\n",
        "        self.df = pd.read_csv(dataset_path,delimiter='\\t',names=['English','German']).values\n",
        "        self.num_samples=num_samples\n",
        "\n",
        "        self.idx_sentences_source= {}\n",
        "        self.idx_sentences_target= {}\n",
        "\n",
        "        self.punctuation_marks = [\n",
        "    '.', ',', ';', ':', '!', '?', '-', '—', '(', ')', '[', ']', '{', '}',\n",
        "    \"'\", '\"', '...', '“', '”', '‘', '’', '/', '\\\\', '|', '@', '#', '$', '%',\n",
        "    '^', '&', '*', '_', '=', '+', '<', '>', '`', '~'\n",
        "]\n",
        "\n",
        "        idx=0\n",
        "        for row in self.df:\n",
        "            source_sentence = row[1]\n",
        "            #if 'Tom' in source_sentence: continue\n",
        "\n",
        "            target_sentence = row[0]\n",
        "\n",
        "            if source_sentence[-1] in self.punctuation_marks: source_sentence=source_sentence[:-1]\n",
        "            if target_sentence[-1] in self.punctuation_marks: target_sentence=target_sentence[:-1]\n",
        "\n",
        "            self.idx_sentences_source[idx]=source_sentence\n",
        "            self.idx_sentences_target[idx]=target_sentence\n",
        "\n",
        "            idx+=1\n",
        "            if idx==self.num_samples: break\n",
        "\n",
        "\n",
        "        self.vocab = Vocabulary(freq_threshold)\n",
        "        self.vocab.build_vocabulary(self.idx_sentences_source.values(),'source')\n",
        "        self.vocab.build_vocabulary(self.idx_sentences_target.values(),'target')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx_sentences_source)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        source_sentence = self.idx_sentences_source[index]\n",
        "        target_sentence = self.idx_sentences_target[index]\n",
        "\n",
        "        #numericalised source sentence\n",
        "        numericalized_caption_source= [self.vocab.stoi_source[\"<SOS>\"]] + self.vocab.numericalize(source_sentence,key='source') + [self.vocab.stoi_source[\"<EOS>\"]]\n",
        "\n",
        "        #numericalised target sentence\n",
        "        numericalized_caption_target= [self.vocab.stoi_target[\"<SOS>\"]] + self.vocab.numericalize(target_sentence,key='target') + [self.vocab.stoi_target[\"<EOS>\"]]\n",
        "\n",
        "        return torch.tensor(numericalized_caption_source), torch.tensor(numericalized_caption_target)"
      ],
      "metadata": {
        "id": "ECG_R0CASSEO"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TdSpUVlX_oZl"
      },
      "outputs": [],
      "source": [
        "class MyCollate:\n",
        "    def __init__(self, pad_idx):\n",
        "        self.pad_idx = pad_idx\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        sources=[item[0] for item in batch]\n",
        "        sources=pad_sequence(sources, batch_first=False, padding_value=self.pad_idx)\n",
        "\n",
        "        targets = [item[1] for item in batch]\n",
        "        targets = pad_sequence(targets, batch_first=False, padding_value=self.pad_idx)\n",
        "\n",
        "        return sources, targets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loader(\n",
        "    dataset_path,num_samples=28000,\n",
        "    freq_threshold=2,\n",
        "    batch_size=32,\n",
        "    num_workers=8,\n",
        "    shuffle=True,\n",
        "    pin_memory=True,\n",
        "):\n",
        "    dataset = seq2seq_dataset(dataset_path=dataset_path, num_samples=num_samples,freq_threshold=freq_threshold)\n",
        "\n",
        "    pad_idx = dataset.vocab.stoi_source[\"<PAD>\"]\n",
        "\n",
        "    loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        shuffle=shuffle,\n",
        "        pin_memory=pin_memory,\n",
        "        collate_fn=MyCollate(pad_idx=pad_idx),\n",
        "    )\n",
        "\n",
        "    return loader, dataset"
      ],
      "metadata": {
        "id": "8HGNLSQhUIq6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WLXCdb3_pMQ"
      },
      "source": [
        "####Dataset Testing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, dataset = get_loader(dataset_path='/content/drive/MyDrive/Seq2SeqModel/dataset.txt',\n",
        "                                   num_samples=99968,freq_threshold=2,batch_size=64,num_workers=2)"
      ],
      "metadata": {
        "id": "IcRHL1qCWK6H"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfEbFkuEWffw",
        "outputId": "198b5877-68c8-4ca4-b044-5f201c6fd990"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99968"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_idx,(sources,targets) in enumerate(train_loader):\n",
        "  break"
      ],
      "metadata": {
        "id": "V2YNOdxjyBaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4179db69-07f8-4122-bd8e-ab3e6836b8f0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkP74uHvGTmV",
        "outputId": "5b5025c7-d7d4-4de2-9b99-4d048c55fe5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch no.: 6:-\n",
            "Sample 9 of Batch 6\n",
            "Source Shape: torch.Size([11, 64])\n",
            "Target Shape: torch.Size([11, 64])\n",
            "Source Sentence: \"<SOS> wie alt schätzt ihr sie <EOS> <PAD> <PAD> <PAD> <PAD>\" with length: 11\n",
            "Target Sentence: \"<SOS> how old do you think she is <EOS> <PAD> <PAD>\" with length: 11\n"
          ]
        }
      ],
      "source": [
        "batch_chk_idx=5\n",
        "for batch_idx,(sources,targets) in enumerate(train_loader):\n",
        "  if batch_idx==batch_chk_idx:break\n",
        "print(f'Batch no.: {batch_idx+1}:-')\n",
        "\n",
        "source_sentence=''\n",
        "num_words_source=0\n",
        "chk_idx=8\n",
        "\n",
        "print(f'Sample {chk_idx+1} of Batch {batch_idx+1}')\n",
        "print(f'Source Shape: {sources.shape}')\n",
        "print(f'Target Shape: {targets.shape}')\n",
        "\n",
        "for source_idx in sources[:,chk_idx]:\n",
        "  num_words_source+=1\n",
        "  source_sentence+=dataset.vocab.itos_source[source_idx.item()]+' '\n",
        "\n",
        "target_sentence=''\n",
        "num_words_target=0\n",
        "for target_idx in targets[:,chk_idx]:\n",
        "  num_words_target+=1\n",
        "  target_sentence+=dataset.vocab.itos_target[target_idx.item()]+' '\n",
        "source_sentence=source_sentence[:-1]\n",
        "target_sentence=target_sentence[:-1]\n",
        "\n",
        "print(f'Source Sentence: \"{source_sentence}\" with length: {num_words_source}')\n",
        "print(f'Target Sentence: \"{target_sentence}\" with length: {num_words_target}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhCm_g3AHg2C",
        "outputId": "93363eff-0261-4801-c43f-8ae54c826349"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "'\\n' in dataset.vocab.itos_target"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model"
      ],
      "metadata": {
        "id": "Tbk3wodxN2XJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,vocab_size,num_layers=1):\n",
        "    super(EncoderRNN,self).__init__()\n",
        "    self.embed=nn.Embedding(num_embeddings=vocab_size,embedding_dim=input_size)\n",
        "    self.lstm=nn.LSTM(input_size=input_size,hidden_size=hidden_size,num_layers=num_layers,dropout=0.5)\n",
        "    self.dropout=nn.Dropout(p=0.5)\n",
        "\n",
        "\n",
        "  def forward(self,source_sentence):\n",
        "    #source_sentence dim: (seq_len,batch)\n",
        "\n",
        "    embeddings=self.dropout(self.embed(source_sentence))\n",
        "    #embeddings dim: (seq_len,batch,input_size)\n",
        "\n",
        "    outputs,(hidden_state,cell_state)=self.lstm(embeddings)\n",
        "    #output dim: (seq_len,batch,hidden_size)\n",
        "    #hidden_state/cell_state dim: (num_layers,batch,hidden_size)\n",
        "\n",
        "    return hidden_state,cell_state"
      ],
      "metadata": {
        "id": "euxh54p5BVLT"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,vocab_size,num_layers=1):\n",
        "    super(DecoderRNN,self).__init__()\n",
        "    self.embed=nn.Embedding(num_embeddings=vocab_size,embedding_dim=input_size)\n",
        "    self.lstm=nn.LSTM(input_size=input_size,hidden_size=hidden_size,num_layers=num_layers,dropout=0.5)\n",
        "    self.linear=nn.Linear(in_features=hidden_size,out_features=vocab_size)\n",
        "    self.dropout=nn.Dropout(p=0.5)\n",
        "\n",
        "\n",
        "  def forward(self,word_idx,hidden_state,cell_state):\n",
        "    #word_vector dim: (batch,)\n",
        "    #hidden_state/cell_state dim: (num_layers,batch,hidden_size)\n",
        "\n",
        "    embedding=self.dropout(self.embed(word_idx.unsqueeze(0)))\n",
        "    #embeddingdim: (1,batch,input_size)\n",
        "\n",
        "    output,(hidden_state,cell_state)=self.lstm(embedding,(hidden_state,cell_state))\n",
        "    #output dim: (1,batch,hidden_size)\n",
        "    #hidden_state/cell_state dim: (num_layers,batch,hidden_size)\n",
        "\n",
        "    predicted_word=self.linear(output).squeeze(0)\n",
        "    #predicted_word dim: (batch,vocab_size)\n",
        "\n",
        "    return predicted_word,hidden_state,cell_state"
      ],
      "metadata": {
        "id": "rji1avkrBY8V"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,vocab_size_source,vocab_size_target,num_layers=1):\n",
        "    super(Seq2Seq,self).__init__()\n",
        "    self.encoder=EncoderRNN(input_size=input_size,hidden_size=hidden_size,vocab_size=vocab_size_source,num_layers=num_layers)\n",
        "    self.decoder=DecoderRNN(input_size=input_size,hidden_size=hidden_size,vocab_size=vocab_size_target,num_layers=num_layers)\n",
        "    self.vocab_size_source=vocab_size_source\n",
        "    self.vocab_size_target=vocab_size_target\n",
        "\n",
        "  def forward(self,source_sentences,target_sentences,teacher_forcer_ratio=0.5):\n",
        "    #source/target sentence dim: (seq_len,batch)\n",
        "\n",
        "    hidden_state,cell_state=self.encoder(source_sentences)\n",
        "    #hidden_state/cell_state dim: (num_layers,batch,hidden_size)\n",
        "\n",
        "    target_len,batch_size=target_sentences.shape\n",
        "    outputs=torch.zeros(size=(target_len,batch_size,self.vocab_size_target))\n",
        "    input_word=target_sentences[0]\n",
        "    #input_word dim: (batch, )\n",
        "\n",
        "    for idx in range(1,target_len):\n",
        "      prediction,hidden_state,cell_state=self.decoder(input_word,hidden_state,cell_state)\n",
        "      outputs[idx]=prediction\n",
        "\n",
        "      if random.random()<teacher_forcer_ratio:\n",
        "        input_word=target_sentences[idx]\n",
        "      else:\n",
        "        input_word=prediction.argmax(dim=1)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "  def translate(self,source_sentence,vocab_target,device,max_len=50):\n",
        "    #source_sentence dim: (seq_len,)\n",
        "\n",
        "    hidden_state,cell_state=self.encoder(source_sentence.unsqueeze(1).to(device))\n",
        "    #hidden_state/cell_state dim: (num_layers,batch,hidden_size)\n",
        "\n",
        "    translated='<SOS> '\n",
        "    input_word=torch.tensor([source_sentence[0].item(),])\n",
        "    #input_word dim: (1,)\n",
        "\n",
        "    for pred in range(max_len):\n",
        "      prediction,hidden_state,cell_state=self.decoder(input_word.to(device),hidden_state.to(device),cell_state.to(device))\n",
        "      #prediction dim: (1,vocab_size)\n",
        "\n",
        "      word_idx=prediction.argmax(dim=1)\n",
        "      #word_idx dim: (1,)\n",
        "\n",
        "      translated+=vocab_target[word_idx.item()]+' '\n",
        "\n",
        "      if vocab_target[word_idx.item()]=='<EOS>': break\n",
        "\n",
        "      input_word=torch.tensor([word_idx.item(),])\n",
        "\n",
        "    return translated[:-1]\n"
      ],
      "metadata": {
        "id": "6eL5QRxtBtOR"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training"
      ],
      "metadata": {
        "id": "_GchhGtKFMnf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialisation"
      ],
      "metadata": {
        "id": "elGuVpXGGyVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#hyper-parameters\n",
        "num_epochs=40\n",
        "lr=1e-3\n",
        "batch_size=64\n",
        "input_size,hidden_size=256,1024\n",
        "num_samples=99968\n",
        "num_layers=1\n",
        "freq_threshold=2\n",
        "dataset_path='/content/drive/MyDrive/Seq2SeqModel/dataset.txt'\n",
        "\n",
        "#dataset\n",
        "train_loader,dataset=get_loader(dataset_path=dataset_path,num_samples=num_samples,freq_threshold=freq_threshold,batch_size=batch_size)\n",
        "\n",
        "#model\n",
        "#min_loss=np.Inf\n",
        "save_path='/content/drive/MyDrive/Seq2SeqModel/model'\n",
        "model=Seq2Seq(input_size=input_size,hidden_size=hidden_size,vocab_size_source=len(dataset.vocab.itos_source),vocab_size_target=len(dataset.vocab.itos_target),num_layers=num_layers).to(device)\n",
        "min_loss=torch.load('/content/drive/MyDrive/Seq2SeqModel/model.pth',map_location=device)['loss']\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Seq2SeqModel/model.pth',map_location=device)['model_state_dict'])\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=lr)\n",
        "criterion=nn.CrossEntropyLoss(ignore_index=dataset.vocab.stoi_target['<PAD>'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Usd0XPRWzzr",
        "outputId": "21e9368a-66d3-46ff-ad6b-2561cd5acbc8"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hwG_stpSLRa",
        "outputId": "cd08c515-1dff-4d34-ec34-4a284f821120"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6902420901038735"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#validation sentence\n",
        "chk_idx=25000\n",
        "source,target=dataset[chk_idx]\n",
        "\n",
        "validation_sentence_source=''\n",
        "for word_idx in source:\n",
        "  validation_sentence_source+=dataset.vocab.itos_source[word_idx.item()]+' '\n",
        "print(f'Source sentence: {validation_sentence_source[:-1]}')\n",
        "\n",
        "validation_sentence_target=''\n",
        "for word_idx in target:\n",
        "  validation_sentence_target+=dataset.vocab.itos_target[word_idx.item()]+' '\n",
        "print(f'Target sentence: {validation_sentence_target[:-1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYH_4e1Ame-p",
        "outputId": "107853fc-abed-4a5b-c279-c767c5f07172"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source sentence: <SOS> bitte setzen sie sich <EOS>\n",
            "Target sentence: <SOS> please have a seat <EOS>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Checkpoint"
      ],
      "metadata": {
        "id": "ZSF6N4-sULqY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(epoch,model,loss,optimiser,path):\n",
        "  save_path=path+'.pth'\n",
        "  torch.save({\n",
        "      'epoch':epoch,\n",
        "      'model_state_dict':model.state_dict(),\n",
        "      'optimizer_state_dict':optimiser.state_dict(),\n",
        "      'loss':loss\n",
        "  },save_path)"
      ],
      "metadata": {
        "id": "9kysYvj6ULTL"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Block"
      ],
      "metadata": {
        "id": "alBtUxKNG0qO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Actual sentence: {validation_sentence_target[:-1]}')\n",
        "epoch_losses=[]\n",
        "model.train()\n",
        "num_batches=len(train_loader)\n",
        "for epoch in range(1,num_epochs+1):\n",
        "  batch_losses=[]\n",
        "  print(f'Epoch {epoch} begins:-\\n')\n",
        "  for batch_idx,(source_sentences,target_sentences) in enumerate(train_loader):\n",
        "    inputs=source_sentences.to(device)\n",
        "    targets=target_sentences.to(device)\n",
        "\n",
        "    outputs=model(inputs,targets).to(device)\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss=criterion(outputs[1:].reshape(-1,outputs.shape[2]),targets[1:].reshape(-1))\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(),max_norm=1)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    batch_losses.append(loss.item())\n",
        "\n",
        "    if (batch_idx+1)%100==0:\n",
        "      print(f'Epoch {epoch}/{num_epochs}, Batch {batch_idx+1}/{num_batches}, Batch Loss: {batch_losses[-1]:.4f}')\n",
        "\n",
        "      translated_sentence=model.translate(source.to(device),dataset.vocab.itos_target,device)\n",
        "      print(f'Translated sentence: {translated_sentence}\\n')\n",
        "\n",
        "  epoch_losses.append(np.mean(batch_losses))\n",
        "  print(f'\\nEpoch {epoch}/{num_epochs}, Epoch Loss: {epoch_losses[-1]:.4f}')\n",
        "  current_epoch_loss=epoch_losses[-1]\n",
        "  if current_epoch_loss<min_loss:\n",
        "    print(f'Epoch Loss improved from {min_loss:.4f} to {current_epoch_loss:.4f}')\n",
        "    min_loss=current_epoch_loss\n",
        "    save_checkpoint(epoch,model,current_epoch_loss,optimizer,save_path)\n",
        "    print(f'Improved Model saved at \"{save_path}\"\\n')\n",
        "\n",
        "\n",
        "  print(f'Epoch {epoch} ends!!\\n\\n')"
      ],
      "metadata": {
        "id": "mfciZM3JGxhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Testing Arena"
      ],
      "metadata": {
        "id": "UyV7LITzOE3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Vocab size of source is: {len(dataset.vocab.itos_source)} and that of target is: {len(dataset.vocab.itos_target)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zhl8YQi-SyIF",
        "outputId": "8a81be3f-a1e8-4682-8182-2fbde189ee0f"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size of source is: 9918 and that of target is: 6525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_chk_samples=100\n",
        "idx=0\n",
        "for sample in range(1,num_chk_samples+1):\n",
        "  #idx=random.randint(0,num_samples)\n",
        "  print(f'Sample no. {sample}, Dataset Index {idx}:-')\n",
        "  source,target=dataset[idx]\n",
        "  idx+=1\n",
        "  validation_sentence_source=''\n",
        "  for word_idx in source:\n",
        "    validation_sentence_source+=dataset.vocab.itos_source[word_idx.item()]+' '\n",
        "  validation_sentence_source=validation_sentence_source[:-1]\n",
        "  validation_sentence_target=''\n",
        "  validation_sentence_output=model.translate(source,dataset.vocab.itos_target,device)\n",
        "  for word in target:\n",
        "    validation_sentence_target+=dataset.vocab.itos_target[word.item()]+' '\n",
        "  validation_sentence_target=validation_sentence_target[:-1]\n",
        "\n",
        "  print(f'Source Sentence: {validation_sentence_source}')\n",
        "  print(f'Target Sentence: {validation_sentence_target}')\n",
        "  print(f'Translated Sentence: {validation_sentence_output}\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qf91gFs0pa4Z",
        "outputId": "1fa77f9d-91f0-4759-d56a-49810c61a659"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample no. 1, Dataset Index 0:-\n",
            "Source Sentence: <SOS> hallo <EOS>\n",
            "Target Sentence: <SOS> hi <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 2, Dataset Index 1:-\n",
            "Source Sentence: <SOS> grüß gott <EOS>\n",
            "Target Sentence: <SOS> hi <EOS>\n",
            "Translated Sentence: <SOS> is some <EOS>\n",
            "\n",
            "\n",
            "Sample no. 3, Dataset Index 2:-\n",
            "Source Sentence: <SOS> lauf <EOS>\n",
            "Target Sentence: <SOS> run <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 4, Dataset Index 3:-\n",
            "Source Sentence: <SOS> potzdonner <EOS>\n",
            "Target Sentence: <SOS> wow <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 5, Dataset Index 4:-\n",
            "Source Sentence: <SOS> <UNK> <EOS>\n",
            "Target Sentence: <SOS> wow <EOS>\n",
            "Translated Sentence: <SOS> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 6, Dataset Index 5:-\n",
            "Source Sentence: <SOS> feuer <EOS>\n",
            "Target Sentence: <SOS> fire <EOS>\n",
            "Translated Sentence: <SOS> fire <EOS>\n",
            "\n",
            "\n",
            "Sample no. 7, Dataset Index 6:-\n",
            "Source Sentence: <SOS> hilfe <EOS>\n",
            "Target Sentence: <SOS> help <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 8, Dataset Index 7:-\n",
            "Source Sentence: <SOS> zu <UNK> <EOS>\n",
            "Target Sentence: <SOS> help <EOS>\n",
            "Translated Sentence: <SOS> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 9, Dataset Index 8:-\n",
            "Source Sentence: <SOS> stopp <EOS>\n",
            "Target Sentence: <SOS> stop <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 10, Dataset Index 9:-\n",
            "Source Sentence: <SOS> warte <EOS>\n",
            "Target Sentence: <SOS> wait <EOS>\n",
            "Translated Sentence: <SOS> wait <EOS>\n",
            "\n",
            "\n",
            "Sample no. 11, Dataset Index 10:-\n",
            "Source Sentence: <SOS> mach weiter <EOS>\n",
            "Target Sentence: <SOS> go on <EOS>\n",
            "Translated Sentence: <SOS> go on <EOS>\n",
            "\n",
            "\n",
            "Sample no. 12, Dataset Index 11:-\n",
            "Source Sentence: <SOS> hallo <EOS>\n",
            "Target Sentence: <SOS> hello <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 13, Dataset Index 12:-\n",
            "Source Sentence: <SOS> ich rannte <EOS>\n",
            "Target Sentence: <SOS> i ran <EOS>\n",
            "Translated Sentence: <SOS> ran <EOS>\n",
            "\n",
            "\n",
            "Sample no. 14, Dataset Index 13:-\n",
            "Source Sentence: <SOS> ich verstehe <EOS>\n",
            "Target Sentence: <SOS> i see <EOS>\n",
            "Translated Sentence: <SOS> i understand <EOS>\n",
            "\n",
            "\n",
            "Sample no. 15, Dataset Index 14:-\n",
            "Source Sentence: <SOS> <UNK> <EOS>\n",
            "Target Sentence: <SOS> i see <EOS>\n",
            "Translated Sentence: <SOS> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 16, Dataset Index 15:-\n",
            "Source Sentence: <SOS> ich probiere es <EOS>\n",
            "Target Sentence: <SOS> i try <EOS>\n",
            "Translated Sentence: <SOS> i 'll check <EOS>\n",
            "\n",
            "\n",
            "Sample no. 17, Dataset Index 16:-\n",
            "Source Sentence: <SOS> ich hab gewonnen <EOS>\n",
            "Target Sentence: <SOS> i won <EOS>\n",
            "Translated Sentence: <SOS> i won <EOS>\n",
            "\n",
            "\n",
            "Sample no. 18, Dataset Index 17:-\n",
            "Source Sentence: <SOS> ich habe gewonnen <EOS>\n",
            "Target Sentence: <SOS> i won <EOS>\n",
            "Translated Sentence: <SOS> it won <EOS>\n",
            "\n",
            "\n",
            "Sample no. 19, Dataset Index 18:-\n",
            "Source Sentence: <SOS> lächeln <EOS>\n",
            "Target Sentence: <SOS> smile <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 20, Dataset Index 19:-\n",
            "Source Sentence: <SOS> zum wohl <EOS>\n",
            "Target Sentence: <SOS> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> to try <EOS>\n",
            "\n",
            "\n",
            "Sample no. 21, Dataset Index 20:-\n",
            "Source Sentence: <SOS> keine bewegung <EOS>\n",
            "Target Sentence: <SOS> freeze <EOS>\n",
            "Translated Sentence: <SOS> do n't change <EOS>\n",
            "\n",
            "\n",
            "Sample no. 22, Dataset Index 21:-\n",
            "Source Sentence: <SOS> stehenbleiben <EOS>\n",
            "Target Sentence: <SOS> freeze <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 23, Dataset Index 22:-\n",
            "Source Sentence: <SOS> kapiert <EOS>\n",
            "Target Sentence: <SOS> got it <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 24, Dataset Index 23:-\n",
            "Source Sentence: <SOS> verstanden <EOS>\n",
            "Target Sentence: <SOS> got it <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 25, Dataset Index 24:-\n",
            "Source Sentence: <SOS> einverstanden <EOS>\n",
            "Target Sentence: <SOS> got it <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 26, Dataset Index 25:-\n",
            "Source Sentence: <SOS> er rannte <EOS>\n",
            "Target Sentence: <SOS> he ran <EOS>\n",
            "Translated Sentence: <SOS> he ran <EOS>\n",
            "\n",
            "\n",
            "Sample no. 27, Dataset Index 26:-\n",
            "Source Sentence: <SOS> er lief <EOS>\n",
            "Target Sentence: <SOS> he ran <EOS>\n",
            "Translated Sentence: <SOS> he ran away <EOS>\n",
            "\n",
            "\n",
            "Sample no. 28, Dataset Index 27:-\n",
            "Source Sentence: <SOS> mach mit <EOS>\n",
            "Target Sentence: <SOS> <UNK> in <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 29, Dataset Index 28:-\n",
            "Source Sentence: <SOS> drück mich <EOS>\n",
            "Target Sentence: <SOS> hug me <EOS>\n",
            "Translated Sentence: <SOS> help me <EOS>\n",
            "\n",
            "\n",
            "Sample no. 30, Dataset Index 29:-\n",
            "Source Sentence: <SOS> nimm mich in den arm <EOS>\n",
            "Target Sentence: <SOS> hug me <EOS>\n",
            "Translated Sentence: <SOS> take me to hug <EOS>\n",
            "\n",
            "\n",
            "Sample no. 31, Dataset Index 30:-\n",
            "Source Sentence: <SOS> umarme mich <EOS>\n",
            "Target Sentence: <SOS> hug me <EOS>\n",
            "Translated Sentence: <SOS> for me <EOS>\n",
            "\n",
            "\n",
            "Sample no. 32, Dataset Index 31:-\n",
            "Source Sentence: <SOS> ich fiel <EOS>\n",
            "Target Sentence: <SOS> i fell <EOS>\n",
            "Translated Sentence: <SOS> i fell <EOS>\n",
            "\n",
            "\n",
            "Sample no. 33, Dataset Index 32:-\n",
            "Source Sentence: <SOS> ich fiel hin <EOS>\n",
            "Target Sentence: <SOS> i fell <EOS>\n",
            "Translated Sentence: <SOS> was accepted <EOS>\n",
            "\n",
            "\n",
            "Sample no. 34, Dataset Index 33:-\n",
            "Source Sentence: <SOS> ich stürzte <EOS>\n",
            "Target Sentence: <SOS> i fell <EOS>\n",
            "Translated Sentence: <SOS> i walked <EOS>\n",
            "\n",
            "\n",
            "Sample no. 35, Dataset Index 34:-\n",
            "Source Sentence: <SOS> ich bin hingefallen <EOS>\n",
            "Target Sentence: <SOS> i fell <EOS>\n",
            "Translated Sentence: <SOS> i 'm <EOS>\n",
            "\n",
            "\n",
            "Sample no. 36, Dataset Index 35:-\n",
            "Source Sentence: <SOS> ich bin gestürzt <EOS>\n",
            "Target Sentence: <SOS> i fell <EOS>\n",
            "Translated Sentence: <SOS> i fell <EOS>\n",
            "\n",
            "\n",
            "Sample no. 37, Dataset Index 36:-\n",
            "Source Sentence: <SOS> ich weiß <EOS>\n",
            "Target Sentence: <SOS> i know <EOS>\n",
            "Translated Sentence: <SOS> i <EOS>\n",
            "\n",
            "\n",
            "Sample no. 38, Dataset Index 37:-\n",
            "Source Sentence: <SOS> ich habe gelogen <EOS>\n",
            "Target Sentence: <SOS> i lied <EOS>\n",
            "Translated Sentence: <SOS> i was <EOS>\n",
            "\n",
            "\n",
            "Sample no. 39, Dataset Index 38:-\n",
            "Source Sentence: <SOS> ich habe verloren <EOS>\n",
            "Target Sentence: <SOS> i lost <EOS>\n",
            "Translated Sentence: <SOS> i lost my mind <EOS>\n",
            "\n",
            "\n",
            "Sample no. 40, Dataset Index 39:-\n",
            "Source Sentence: <SOS> ich habe bezahlt <EOS>\n",
            "Target Sentence: <SOS> i paid <EOS>\n",
            "Translated Sentence: <SOS> it paid <EOS>\n",
            "\n",
            "\n",
            "Sample no. 41, Dataset Index 40:-\n",
            "Source Sentence: <SOS> ich zahlte <EOS>\n",
            "Target Sentence: <SOS> i paid <EOS>\n",
            "Translated Sentence: <SOS> help <EOS>\n",
            "\n",
            "\n",
            "Sample no. 42, Dataset Index 41:-\n",
            "Source Sentence: <SOS> ich sang <EOS>\n",
            "Target Sentence: <SOS> i sang <EOS>\n",
            "Translated Sentence: <SOS> i sang <EOS>\n",
            "\n",
            "\n",
            "Sample no. 43, Dataset Index 42:-\n",
            "Source Sentence: <SOS> ich schwimme <EOS>\n",
            "Target Sentence: <SOS> i swim <EOS>\n",
            "Translated Sentence: <SOS> i swim <EOS>\n",
            "\n",
            "\n",
            "Sample no. 44, Dataset Index 43:-\n",
            "Source Sentence: <SOS> ich bin 19 jahre alt <EOS>\n",
            "Target Sentence: <SOS> i 'm 19 <EOS>\n",
            "Translated Sentence: <SOS> i 'm 19 years old <EOS>\n",
            "\n",
            "\n",
            "Sample no. 45, Dataset Index 44:-\n",
            "Source Sentence: <SOS> ich bin 19 <EOS>\n",
            "Target Sentence: <SOS> i 'm 19 <EOS>\n",
            "Translated Sentence: <SOS> i 'm 19 <EOS>\n",
            "\n",
            "\n",
            "Sample no. 46, Dataset Index 45:-\n",
            "Source Sentence: <SOS> mir geht's gut <EOS>\n",
            "Target Sentence: <SOS> i 'm ok <EOS>\n",
            "Translated Sentence: <SOS> i 'm fine <EOS>\n",
            "\n",
            "\n",
            "Sample no. 47, Dataset Index 46:-\n",
            "Source Sentence: <SOS> es geht mir gut <EOS>\n",
            "Target Sentence: <SOS> i 'm ok <EOS>\n",
            "Translated Sentence: <SOS> i 'm fine <EOS>\n",
            "\n",
            "\n",
            "Sample no. 48, Dataset Index 47:-\n",
            "Source Sentence: <SOS> ich bin wach <EOS>\n",
            "Target Sentence: <SOS> i 'm up <EOS>\n",
            "Translated Sentence: <SOS> i awake awake <EOS>\n",
            "\n",
            "\n",
            "Sample no. 49, Dataset Index 48:-\n",
            "Source Sentence: <SOS> ich bin auf <EOS>\n",
            "Target Sentence: <SOS> i 'm up <EOS>\n",
            "Translated Sentence: <SOS> i 'm up <EOS>\n",
            "\n",
            "\n",
            "Sample no. 50, Dataset Index 49:-\n",
            "Source Sentence: <SOS> unmöglich <EOS>\n",
            "Target Sentence: <SOS> no way <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 51, Dataset Index 50:-\n",
            "Source Sentence: <SOS> das kommt nicht in frage <EOS>\n",
            "Target Sentence: <SOS> no way <EOS>\n",
            "Translated Sentence: <SOS> that is n't coming <EOS>\n",
            "\n",
            "\n",
            "Sample no. 52, Dataset Index 51:-\n",
            "Source Sentence: <SOS> das gibt ’s doch nicht <EOS>\n",
            "Target Sentence: <SOS> no way <EOS>\n",
            "Translated Sentence: <SOS> the <UNK> not any true <EOS>\n",
            "\n",
            "\n",
            "Sample no. 53, Dataset Index 52:-\n",
            "Source Sentence: <SOS> ausgeschlossen <EOS>\n",
            "Target Sentence: <SOS> no way <EOS>\n",
            "Translated Sentence: <SOS> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 54, Dataset Index 53:-\n",
            "Source Sentence: <SOS> in <UNK> weise <EOS>\n",
            "Target Sentence: <SOS> no way <EOS>\n",
            "Translated Sentence: <SOS> <UNK> eat in <EOS>\n",
            "\n",
            "\n",
            "Sample no. 55, Dataset Index 54:-\n",
            "Source Sentence: <SOS> wirklich <EOS>\n",
            "Target Sentence: <SOS> really <EOS>\n",
            "Translated Sentence: <SOS> really <EOS>\n",
            "\n",
            "\n",
            "Sample no. 56, Dataset Index 55:-\n",
            "Source Sentence: <SOS> echt <EOS>\n",
            "Target Sentence: <SOS> really <EOS>\n",
            "Translated Sentence: <SOS> really <EOS>\n",
            "\n",
            "\n",
            "Sample no. 57, Dataset Index 56:-\n",
            "Source Sentence: <SOS> im ernst <EOS>\n",
            "Target Sentence: <SOS> really <EOS>\n",
            "Translated Sentence: <SOS> seriously <EOS>\n",
            "\n",
            "\n",
            "Sample no. 58, Dataset Index 57:-\n",
            "Source Sentence: <SOS> danke <EOS>\n",
            "Target Sentence: <SOS> thanks <EOS>\n",
            "Translated Sentence: <SOS> thanks <EOS>\n",
            "\n",
            "\n",
            "Sample no. 59, Dataset Index 58:-\n",
            "Source Sentence: <SOS> versuch ’s <EOS>\n",
            "Target Sentence: <SOS> try it <EOS>\n",
            "Translated Sentence: <SOS> do it <EOS>\n",
            "\n",
            "\n",
            "Sample no. 60, Dataset Index 59:-\n",
            "Source Sentence: <SOS> wir haben gewonnen <EOS>\n",
            "Target Sentence: <SOS> we won <EOS>\n",
            "Translated Sentence: <SOS> we won <EOS>\n",
            "\n",
            "\n",
            "Sample no. 61, Dataset Index 60:-\n",
            "Source Sentence: <SOS> warum ich <EOS>\n",
            "Target Sentence: <SOS> why me <EOS>\n",
            "Translated Sentence: <SOS> i i why <EOS>\n",
            "\n",
            "\n",
            "Sample no. 62, Dataset Index 61:-\n",
            "Source Sentence: <SOS> frag tom <EOS>\n",
            "Target Sentence: <SOS> ask tom <EOS>\n",
            "Translated Sentence: <SOS> ask tom <EOS>\n",
            "\n",
            "\n",
            "Sample no. 63, Dataset Index 62:-\n",
            "Source Sentence: <SOS> fragen sie tom <EOS>\n",
            "Target Sentence: <SOS> ask tom <EOS>\n",
            "Translated Sentence: <SOS> ask tom <EOS>\n",
            "\n",
            "\n",
            "Sample no. 64, Dataset Index 63:-\n",
            "Source Sentence: <SOS> fragt tom <EOS>\n",
            "Target Sentence: <SOS> ask tom <EOS>\n",
            "Translated Sentence: <SOS> tom tom <EOS>\n",
            "\n",
            "\n",
            "Sample no. 65, Dataset Index 64:-\n",
            "Source Sentence: <SOS> fantastisch <EOS>\n",
            "Target Sentence: <SOS> awesome <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 66, Dataset Index 65:-\n",
            "Source Sentence: <SOS> entspann dich <EOS>\n",
            "Target Sentence: <SOS> be cool <EOS>\n",
            "Translated Sentence: <SOS> catch a decision <EOS>\n",
            "\n",
            "\n",
            "Sample no. 67, Dataset Index 66:-\n",
            "Source Sentence: <SOS> sei nicht ungerecht <EOS>\n",
            "Target Sentence: <SOS> be fair <EOS>\n",
            "Translated Sentence: <SOS> do n't be used <EOS>\n",
            "\n",
            "\n",
            "Sample no. 68, Dataset Index 67:-\n",
            "Source Sentence: <SOS> sei fair <EOS>\n",
            "Target Sentence: <SOS> be fair <EOS>\n",
            "Translated Sentence: <SOS> be fair <EOS>\n",
            "\n",
            "\n",
            "Sample no. 69, Dataset Index 68:-\n",
            "Source Sentence: <SOS> sei nett <EOS>\n",
            "Target Sentence: <SOS> be nice <EOS>\n",
            "Translated Sentence: <SOS> be nice nice boy <EOS>\n",
            "\n",
            "\n",
            "Sample no. 70, Dataset Index 69:-\n",
            "Source Sentence: <SOS> seien sie nett <EOS>\n",
            "Target Sentence: <SOS> be nice <EOS>\n",
            "Translated Sentence: <SOS> be nice <EOS>\n",
            "\n",
            "\n",
            "Sample no. 71, Dataset Index 70:-\n",
            "Source Sentence: <SOS> geh weg <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> go away <EOS>\n",
            "\n",
            "\n",
            "Sample no. 72, Dataset Index 71:-\n",
            "Source Sentence: <SOS> hau ab <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 73, Dataset Index 72:-\n",
            "Source Sentence: <SOS> verschwinde <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 74, Dataset Index 73:-\n",
            "Source Sentence: <SOS> verdufte <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 75, Dataset Index 74:-\n",
            "Source Sentence: <SOS> mach dich fort <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> go away <EOS>\n",
            "\n",
            "\n",
            "Sample no. 76, Dataset Index 75:-\n",
            "Source Sentence: <SOS> zieh leine <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> is your <EOS>\n",
            "\n",
            "\n",
            "Sample no. 77, Dataset Index 76:-\n",
            "Source Sentence: <SOS> mach dich vom acker <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> make people <EOS>\n",
            "\n",
            "\n",
            "Sample no. 78, Dataset Index 77:-\n",
            "Source Sentence: <SOS> verzieh dich <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 79, Dataset Index 78:-\n",
            "Source Sentence: <SOS> verkrümele dich <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> go away <EOS>\n",
            "\n",
            "\n",
            "Sample no. 80, Dataset Index 79:-\n",
            "Source Sentence: <SOS> troll dich <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> move <EOS>\n",
            "\n",
            "\n",
            "Sample no. 81, Dataset Index 80:-\n",
            "Source Sentence: <SOS> zisch ab <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> get away <EOS>\n",
            "\n",
            "\n",
            "Sample no. 82, Dataset Index 81:-\n",
            "Source Sentence: <SOS> pack dich <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> take <EOS>\n",
            "\n",
            "\n",
            "Sample no. 83, Dataset Index 82:-\n",
            "Source Sentence: <SOS> mach ’ne fliege <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> go away <EOS>\n",
            "\n",
            "\n",
            "Sample no. 84, Dataset Index 83:-\n",
            "Source Sentence: <SOS> schwirr ab <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> get lost <EOS>\n",
            "\n",
            "\n",
            "Sample no. 85, Dataset Index 84:-\n",
            "Source Sentence: <SOS> mach die sause <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> get the facts <EOS>\n",
            "\n",
            "\n",
            "Sample no. 86, Dataset Index 85:-\n",
            "Source Sentence: <SOS> scher dich weg <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> go away <EOS>\n",
            "\n",
            "\n",
            "Sample no. 87, Dataset Index 86:-\n",
            "Source Sentence: <SOS> scher dich fort <EOS>\n",
            "Target Sentence: <SOS> beat it <EOS>\n",
            "Translated Sentence: <SOS> say goodbye <EOS>\n",
            "\n",
            "\n",
            "Sample no. 88, Dataset Index 87:-\n",
            "Source Sentence: <SOS> ruf mich an <EOS>\n",
            "Target Sentence: <SOS> call me <EOS>\n",
            "Translated Sentence: <SOS> call me <EOS>\n",
            "\n",
            "\n",
            "Sample no. 89, Dataset Index 88:-\n",
            "Source Sentence: <SOS> komm herein <EOS>\n",
            "Target Sentence: <SOS> come in <EOS>\n",
            "Translated Sentence: <SOS> come in <EOS>\n",
            "\n",
            "\n",
            "Sample no. 90, Dataset Index 89:-\n",
            "Source Sentence: <SOS> herein <EOS>\n",
            "Target Sentence: <SOS> come in <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 91, Dataset Index 90:-\n",
            "Source Sentence: <SOS> komm <EOS>\n",
            "Target Sentence: <SOS> come on <EOS>\n",
            "Translated Sentence: <SOS> come <EOS>\n",
            "\n",
            "\n",
            "Sample no. 92, Dataset Index 91:-\n",
            "Source Sentence: <SOS> kommt <EOS>\n",
            "Target Sentence: <SOS> come on <EOS>\n",
            "Translated Sentence: <SOS> come <EOS>\n",
            "\n",
            "\n",
            "Sample no. 93, Dataset Index 92:-\n",
            "Source Sentence: <SOS> mach schon <EOS>\n",
            "Target Sentence: <SOS> come on <EOS>\n",
            "Translated Sentence: <SOS> come on <EOS>\n",
            "\n",
            "\n",
            "Sample no. 94, Dataset Index 93:-\n",
            "Source Sentence: <SOS> macht schon <EOS>\n",
            "Target Sentence: <SOS> come on <EOS>\n",
            "Translated Sentence: <SOS> try <EOS>\n",
            "\n",
            "\n",
            "Sample no. 95, Dataset Index 94:-\n",
            "Source Sentence: <SOS> komm schon <EOS>\n",
            "Target Sentence: <SOS> come on <EOS>\n",
            "Translated Sentence: <SOS> come on <EOS>\n",
            "\n",
            "\n",
            "Sample no. 96, Dataset Index 95:-\n",
            "Source Sentence: <SOS> hol tom <EOS>\n",
            "Target Sentence: <SOS> get tom <EOS>\n",
            "Translated Sentence: <SOS> get out <EOS>\n",
            "\n",
            "\n",
            "Sample no. 97, Dataset Index 96:-\n",
            "Source Sentence: <SOS> raus <EOS>\n",
            "Target Sentence: <SOS> get out <EOS>\n",
            "Translated Sentence: <SOS> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 98, Dataset Index 97:-\n",
            "Source Sentence: <SOS> geht raus <EOS>\n",
            "Target Sentence: <SOS> get out <EOS>\n",
            "Translated Sentence: <SOS> get out <EOS>\n",
            "\n",
            "\n",
            "Sample no. 99, Dataset Index 98:-\n",
            "Source Sentence: <SOS> geh raus <EOS>\n",
            "Target Sentence: <SOS> get out <EOS>\n",
            "Translated Sentence: <SOS> go out <EOS>\n",
            "\n",
            "\n",
            "Sample no. 100, Dataset Index 99:-\n",
            "Source Sentence: <SOS> geht raus <EOS>\n",
            "Target Sentence: <SOS> get out <EOS>\n",
            "Translated Sentence: <SOS> get out <EOS>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot([i for i in range(1,len(epoch_losses)+1)],epoch_losses)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs Epochs')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VYwUnmzJulSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_inp='Wie geht es dir'\n",
        "source_word_idxs=[dataset.vocab.stoi_source['<SOS>'],]\n",
        "for word in [tok.text.lower() for tok in spacy_ger.tokenizer(source_inp)]:\n",
        "  source_word_idxs.append(dataset.vocab.stoi_source[word])\n",
        "source_word_idxs.append(dataset.vocab.stoi_source['<EOS>'])\n",
        "source_word_idxs=torch.tensor(source_word_idxs)\n",
        "\n",
        "translated_sentence=model.translate(source_word_idxs,dataset.vocab.itos_target,device)\n",
        "\n",
        "target_sentence='<SOS> '+'how do you do'+' <EOS>'\n",
        "print(f'Target sentence: {target_sentence}')\n",
        "print(f'Translated sentence: {translated_sentence}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSdjaYfwYGQI",
        "outputId": "7a0f1445-a55c-4994-be42-082c87def76f"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target sentence: <SOS> how do you do <EOS>\n",
            "Translated sentence: <SOS> how are you <EOS>\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9WLXCdb3_pMQ",
        "Tbk3wodxN2XJ"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPoI7NSE5c6icstcrqbYCd0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}