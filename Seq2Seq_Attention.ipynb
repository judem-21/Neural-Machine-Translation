{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rF7XsLNXhz7V",
        "EpWRmxNq7Sos"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNmP8fIgl5uO4rtd7Dm7w7k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/judem-21/Seq2Seq-Model/blob/main/Seq2Seq_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1PolMPZOEbE"
      },
      "source": [
        "#Seq2Seq Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF7XsLNXhz7V"
      },
      "source": [
        "###Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "me-hNcwXhajQ"
      },
      "outputs": [],
      "source": [
        "import torch,torchvision\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms as transforms\n",
        "#from torch.torchmetrics.text.bleu import BLEUScore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QrDUgehUhzUU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from skimage import io\n",
        "import spacy\n",
        "from PIL import Image\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en\n",
        "!python -m spacy download de_core_news_sm\n",
        "spacy_eng = spacy.load(\"en_core_web_sm\")\n",
        "spacy_ger = spacy.load(\"de_core_news_sm\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsuiniKF8YTK",
        "outputId": "e6e0cbfd-a835-4019-a282-3b580c7ebfe4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting de-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from de-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.10.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyaiSIfV7Soq"
      },
      "source": [
        "###Dataset (Loading and Testing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4s1Vvi77Sor"
      },
      "source": [
        "####Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67eaa9d1-876e-42f7-c177-def3e4b4860b",
        "id": "YEyKvSye7Sor"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FXpEVIhg7Sor"
      },
      "outputs": [],
      "source": [
        "class Vocabulary:\n",
        "    def __init__(self, freq_threshold=3):\n",
        "        self.itos_source = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
        "        self.stoi_source = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
        "\n",
        "        self.itos_target = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n",
        "        self.stoi_target = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n",
        "\n",
        "        self.punctuation_marks = [\n",
        "    '.', ',', ';', ':', '!', '?', '-', '—', '(', ')', '[', ']', '{', '}',\n",
        "    \"'\", '\"', '...', '“', '”', '‘', '’', '/', '\\\\', '|', '@', '#', '$', '%',\n",
        "    '^', '&', '*', '_', '=', '+', '<', '>', '`', '~'\n",
        "]\n",
        "\n",
        "        self.freq_threshold = freq_threshold\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.itos)\n",
        "\n",
        "    @staticmethod\n",
        "    def tokenizer(text,key):\n",
        "      if key=='en':\n",
        "        return [tok.text.lower() for tok in spacy_eng.tokenizer(text)]\n",
        "      else:\n",
        "        return [tok.text.lower() for tok in spacy_ger.tokenizer(text)]\n",
        "\n",
        "    def build_vocabulary(self, sentence_list, key):\n",
        "        frequencies = {}\n",
        "        idx = 4\n",
        "\n",
        "        for sentence in sentence_list:\n",
        "          if key=='source': lookup=self.tokenizer(sentence,'de')\n",
        "          else: lookup=self.tokenizer(sentence,'en')\n",
        "\n",
        "          for word in lookup:\n",
        "            if word=='\\n' or word in self.punctuation_marks: continue\n",
        "\n",
        "            if word not in frequencies:\n",
        "              frequencies[word] = 1\n",
        "\n",
        "            else:\n",
        "              frequencies[word] += 1\n",
        "\n",
        "            if frequencies[word] == self.freq_threshold:\n",
        "              if key=='source':\n",
        "                self.stoi_source[word] = idx\n",
        "                self.itos_source[idx] = word\n",
        "              elif key=='target':\n",
        "                self.stoi_target[word] = idx\n",
        "                self.itos_target[idx] = word\n",
        "              idx += 1\n",
        "\n",
        "    def numericalize(self, text,key):\n",
        "        if key=='source':\n",
        "          tokenized_text = self.tokenizer(text,'de')\n",
        "          return [self.stoi_source[token] if token in self.stoi_source else self.stoi_source[\"<UNK>\"] for token in tokenized_text]\n",
        "        elif key=='target':\n",
        "          tokenized_text = self.tokenizer(text,'en')\n",
        "          return [self.stoi_target[token] if token in self.stoi_target else self.stoi_target[\"<UNK>\"] for token in tokenized_text]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "j-lXo9We7Sor"
      },
      "outputs": [],
      "source": [
        "class seq2seq_dataset(Dataset):\n",
        "    def __init__(self, source_file, target_file, num_samples=29000, freq_threshold=3):\n",
        "        #self.source_file = source_file\n",
        "        self.file_target=open(target_file, 'r', encoding='utf-8')\n",
        "        self.file_source=open(source_file, 'r', encoding='utf-8')\n",
        "        self.df = list(zip(self.file_source,self.file_target))[:num_samples]\n",
        "        #print(f'len_dataset:{len(self.df)}')\n",
        "        #self.transform = transform\n",
        "        self.num_samples=num_samples\n",
        "\n",
        "        self.idx_sentences_source= {}\n",
        "        self.idx_sentences_target= {}\n",
        "        #counter=0\n",
        "        for idx,lines in enumerate(self.df):\n",
        "            #if counter==num_samples: break\n",
        "            source_sentence = lines[0]\n",
        "            target_sentence = lines[1]\n",
        "            self.idx_sentences_source[idx]=source_sentence\n",
        "            self.idx_sentences_target[idx]=target_sentence\n",
        "            #if idx==self.num_samples-1: break\n",
        "            #counter+=1\n",
        "\n",
        "        self.vocab = Vocabulary(freq_threshold)\n",
        "        self.vocab.build_vocabulary(self.idx_sentences_source.values(),'source')\n",
        "        self.vocab.build_vocabulary(self.idx_sentences_target.values(),'target')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx_sentences_source)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        source_sentence = self.idx_sentences_source[index]\n",
        "        target_sentence = self.idx_sentences_target[index]\n",
        "        #selected_caption = self.image_captions[img_id]\n",
        "        #selected_caption = random.choice(captions)\n",
        "\n",
        "        #numericalised source sentence\n",
        "        numericalized_caption_source= [self.vocab.stoi_source[\"<SOS>\"]] + self.vocab.numericalize(source_sentence,key='source') + [self.vocab.stoi_source[\"<EOS>\"]]\n",
        "\n",
        "        #numericalised target sentence\n",
        "        numericalized_caption_target= [self.vocab.stoi_target[\"<SOS>\"]] + self.vocab.numericalize(target_sentence,key='target') + [self.vocab.stoi_target[\"<EOS>\"]]\n",
        "\n",
        "        return torch.tensor(numericalized_caption_source), torch.tensor(numericalized_caption_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "N02T118t7Sor"
      },
      "outputs": [],
      "source": [
        "class MyCollate:\n",
        "    def __init__(self, pad_idx):\n",
        "        self.pad_idx = pad_idx\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        sources=[item[0] for item in batch]\n",
        "        sources=pad_sequence(sources, batch_first=False, padding_value=self.pad_idx)\n",
        "        '''imgs = [item[0].unsqueeze(0) for item in batch]\n",
        "        imgs = torch.cat(imgs, dim=0)'''\n",
        "        targets = [item[1] for item in batch]\n",
        "        targets = pad_sequence(targets, batch_first=False, padding_value=self.pad_idx)\n",
        "\n",
        "        return sources, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4NUiacG47Sor"
      },
      "outputs": [],
      "source": [
        "def get_loader(\n",
        "    source_file,\n",
        "    target_file,num_samples=28000,\n",
        "    freq_threshold=2,\n",
        "    batch_size=32,\n",
        "    num_workers=8,\n",
        "    shuffle=True,\n",
        "    pin_memory=True,\n",
        "):\n",
        "    dataset = seq2seq_dataset(source_file, target_file, num_samples=num_samples,freq_threshold=freq_threshold)\n",
        "\n",
        "    pad_idx = dataset.vocab.stoi_source[\"<PAD>\"]\n",
        "\n",
        "    loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        shuffle=shuffle,\n",
        "        pin_memory=pin_memory,\n",
        "        collate_fn=MyCollate(pad_idx=pad_idx),\n",
        "    )\n",
        "\n",
        "    return loader, dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpWRmxNq7Sos"
      },
      "source": [
        "####Dataset Testing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, dataset = get_loader(dataset_path='/content/drive/MyDrive/Seq2SeqModel/dataset.txt',freq_threshold=2,batch_size=64,num_samples=29768,num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "Q2VJ7n4v7Sos",
        "outputId": "85385c10-22f5-4dea-fb0f-57e017d94d7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "get_loader() got an unexpected keyword argument 'dataset_path'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ba8f67c17250>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Seq2SeqModel/dataset.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfreq_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m29768\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: get_loader() got an unexpected keyword argument 'dataset_path'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "id": "BdumN_gB7Sos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_idx,(sources,targets) in enumerate(train_loader):\n",
        "  break"
      ],
      "metadata": {
        "id": "hB8NSueI7Sos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets.shape"
      ],
      "metadata": {
        "id": "2ToIHQSO7Sos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgmxnExr7Sos"
      },
      "outputs": [],
      "source": [
        "batch_chk_idx=5\n",
        "for batch_idx,(sources,targets) in enumerate(train_loader):\n",
        "  if batch_idx==batch_chk_idx:break\n",
        "print(f'Batch no.: {batch_idx+1}:-')\n",
        "\n",
        "source_sentence=''\n",
        "num_words_source=0\n",
        "chk_idx=8\n",
        "\n",
        "print(f'Sample {chk_idx+1} of Batch {batch_idx+1}')\n",
        "print(f'Source Shape: {sources.shape}')\n",
        "print(f'Target Shape: {targets.shape}')\n",
        "\n",
        "for source_idx in sources[:,chk_idx]:\n",
        "  num_words_source+=1\n",
        "  source_sentence+=dataset.vocab.itos_source[source_idx.item()]+' '\n",
        "\n",
        "target_sentence=''\n",
        "num_words_target=0\n",
        "for target_idx in targets[:,chk_idx]:\n",
        "  num_words_target+=1\n",
        "  target_sentence+=dataset.vocab.itos_target[target_idx.item()]+' '\n",
        "source_sentence=source_sentence[:-1]\n",
        "target_sentence=target_sentence[:-1]\n",
        "\n",
        "print(f'Source Sentence: \"{source_sentence}\" with length: {num_words_source}')\n",
        "print(f'Target Sentence: \"{target_sentence}\" with length: {num_words_target}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NvlDns37Sos"
      },
      "outputs": [],
      "source": [
        "file_english = open('/content/drive/MyDrive/Seq2SeqModel/train.en', 'r', encoding='utf-8')\n",
        "file_german = open('/content/drive/MyDrive/Seq2SeqModel/train.de', 'r', encoding='utf-8')\n",
        "all_sentences=list(zip(file_english,file_german))[:28000]\n",
        "for idx,lines in enumerate(all_sentences):\n",
        "  #idx+=1\n",
        "  if (idx+1)%100==0:\n",
        "    print(f'English: {lines[0]}',end='')\n",
        "    print(f'German: {lines[1]}')\n",
        "print(f'\\nThere are {idx+1} santences in total!!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5Q8ZhXx7Sos"
      },
      "outputs": [],
      "source": [
        "'\\n' in dataset.vocab.itos_target"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model"
      ],
      "metadata": {
        "id": "UgkHFyQ-7Sos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,vocab_size,num_layers=1):\n",
        "    super(EncoderRNN,self).__init__()\n",
        "    self.embed=nn.Embedding(num_embeddings=vocab_size,embedding_dim=input_size)\n",
        "    #print(f'num_layers: {num_layers}')\n",
        "    self.lstm=nn.LSTM(input_size=input_size,hidden_size=hidden_size,num_layers=num_layers,bidirectional=True,dropout=0.5)\n",
        "    #self.linear=nn.linear\n",
        "    self.dropout=nn.Dropout(p=0.5)\n",
        "    self.fc_hidden=nn.Linear(in_features=hidden_size*2,out_features=hidden_size)\n",
        "    self.fc_cell=nn.Linear(in_features=hidden_size*2,out_features=hidden_size)\n",
        "    self.layer_norm_enc=nn.LayerNorm(2*hidden_size)\n",
        "    self.layer_norm_hidden=nn.LayerNorm(hidden_size)\n",
        "\n",
        "  def forward(self,source_sentence):\n",
        "    #source_sentence dim: (seq_len,batch)\n",
        "\n",
        "    embeddings=self.dropout(self.embed(source_sentence))\n",
        "    #embeddings dim: (seq_len,batch,input_size)\n",
        "\n",
        "    encoder_states,(hidden_state,cell_state)=self.lstm(embeddings)\n",
        "    #output dim: (seq_len,batch,2*hidden_size)\n",
        "    #hidden_state/cell_state dim: (2,batch,hidden_size)\n",
        "\n",
        "    hidden=self.fc_hidden(torch.cat((hidden_state[0:1],hidden_state[1:2]),dim=2))\n",
        "    cell=self.fc_cell(torch.cat((cell_state[0:1],cell_state[1:2]),dim=2))\n",
        "    #hiden/cell dim: (1,batch,hidden_state)\n",
        "\n",
        "    encoder_states=self.layer_norm_enc(encoder_states)\n",
        "    hidden=self.layer_norm_hidden(hidden)\n",
        "    cell=self.layer_norm_hidden(cell)\n",
        "\n",
        "    return encoder_states,hidden,cell"
      ],
      "metadata": {
        "id": "J5aJWwqN7Sot"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,vocab_size,num_layers=1):\n",
        "    super(DecoderRNN,self).__init__()\n",
        "    self.embed=nn.Embedding(num_embeddings=vocab_size,embedding_dim=input_size)\n",
        "    #print(f'num_layers: {num_layers}')\n",
        "    self.energy=nn.Linear(in_features=3*hidden_size,out_features=1)\n",
        "    self.softmax=nn.Softmax(dim=0)\n",
        "    self.relu=nn.ReLU()\n",
        "    self.lstm=nn.LSTM(input_size=2*hidden_size+input_size,hidden_size=hidden_size,num_layers=num_layers,dropout=0.5)\n",
        "    self.linear=nn.Linear(in_features=hidden_size,out_features=vocab_size)\n",
        "    self.dropout=nn.Dropout(p=0.5)\n",
        "    self.layer_norm=nn.LayerNorm(hidden_size)\n",
        "\n",
        "  def forward(self,word_idx,enc_states,hidden_state,cell_state):\n",
        "    #word_idx dim: (batch,)\n",
        "    #enc_states dim: (seq_len,batch,2*hidden_size)\n",
        "    #hidden_state/cell_state dim: (1,batch,hidden_size)\n",
        "\n",
        "    embedding=self.dropout(self.embed(word_idx.unsqueeze(0)))\n",
        "    #embeddingdim: (1,batch,input_size)\n",
        "\n",
        "    seq_length=enc_states.shape[0]\n",
        "    h_reshaped=hidden_state.repeat(seq_length,1,1)\n",
        "\n",
        "    energy=self.relu(self.energy(torch.cat((h_reshaped,enc_states),dim=2)))\n",
        "    #energy dim: (seq_len,batch,1)\n",
        "\n",
        "    attention=self.softmax(energy)\n",
        "    #attention dim (seq_len,batch,1)\n",
        "\n",
        "    attention=attention.permute(1,2,0)\n",
        "    #attention dim: (batch,1,seq_len)\n",
        "\n",
        "    enc_states=enc_states.permute(1,0,2)\n",
        "    #enc_states dim: (batch,seq_len,2*hidden_size)\n",
        "\n",
        "    context_vector=torch.bmm(attention,enc_states).permute(1,0,2)\n",
        "    #context_vector dim: (1,batch,2*hidden_size)\n",
        "\n",
        "    lstm_input=torch.cat((context_vector,embedding),dim=2)\n",
        "    #lstm_input dim: (1,batch,2*hidden_size+input_size)\n",
        "\n",
        "    output,(hidden_state,cell_state)=self.lstm(lstm_input,(hidden_state,cell_state))\n",
        "    #output dim: (1,batch,hidden_size)\n",
        "    #hidden_state/cell_state dim: (num_layers,batch,hidden_size)\n",
        "    output=self.layer_norm(output)\n",
        "    hidden_state=self.layer_norm(hidden_state)\n",
        "    cell_state=self.layer_norm(cell_state)\n",
        "\n",
        "    predicted_word=self.linear(output).squeeze(0)\n",
        "    #predicted_word dim: (batch,vocab_size)\n",
        "\n",
        "    #return hidden_state,cell_state\n",
        "    return predicted_word,hidden_state,cell_state"
      ],
      "metadata": {
        "id": "BQDvpWzu7Sot"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self,input_size,hidden_size,vocab_size_source,vocab_size_target,num_layers=1):\n",
        "    super(Seq2Seq,self).__init__()\n",
        "    self.encoder=EncoderRNN(input_size=input_size,hidden_size=hidden_size,vocab_size=vocab_size_source,num_layers=num_layers)\n",
        "    self.decoder=DecoderRNN(input_size=input_size,hidden_size=hidden_size,vocab_size=vocab_size_target,num_layers=num_layers)\n",
        "    self.vocab_size_source=vocab_size_source\n",
        "    self.vocab_size_target=vocab_size_target\n",
        "\n",
        "  def forward(self,source_sentences,target_sentences,teacher_forcer_ratio=0.5):\n",
        "    #source/target sentence dim: (seq_len,batch)\n",
        "\n",
        "    enc_states,hidden_state,cell_state=self.encoder(source_sentences)\n",
        "    #hidden_state/cell_state dim: (num_layers,batch,hidden_size)\n",
        "\n",
        "    target_len,batch_size=target_sentences.shape\n",
        "    outputs=torch.zeros(size=(target_len,batch_size,self.vocab_size_target))\n",
        "    input_word=target_sentences[0]\n",
        "    #input_word dim: (batch, )\n",
        "\n",
        "    for idx in range(1,target_len):\n",
        "      prediction,hidden_state,cell_state=self.decoder(input_word,enc_states,hidden_state,cell_state)\n",
        "      outputs[idx]=prediction\n",
        "\n",
        "      if random.random()<teacher_forcer_ratio:\n",
        "        input_word=target_sentences[idx]\n",
        "      else:\n",
        "        input_word=prediction.argmax(dim=1)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "  def translate(self,source_sentence,vocab_target,device,max_len=50):\n",
        "    #source_sentence dim: (seq_len,)\n",
        "\n",
        "    enc_states,hidden_state,cell_state=self.encoder(source_sentence.unsqueeze(1).to(device))\n",
        "    #hidden_state/cell_state dim: (1,batch,hidden_size)\n",
        "\n",
        "    translated='<SOS> '\n",
        "    input_word=torch.tensor([source_sentence[0].item(),])\n",
        "    #input_word dim: (1,)\n",
        "\n",
        "    for pred in range(max_len):\n",
        "      prediction,hidden_state,cell_state=self.decoder(input_word.to(device),enc_states.to(device),hidden_state.to(device),cell_state.to(device))\n",
        "      #prediction dim: (1,vocab_size)\n",
        "\n",
        "      word_idx=prediction.argmax(dim=1)\n",
        "      #word_idx dim: (1,)\n",
        "\n",
        "      translated+=vocab_target[word_idx.item()]+' '\n",
        "\n",
        "      if vocab_target[word_idx.item()]=='<EOS>': break\n",
        "\n",
        "      input_word=torch.tensor([word_idx.item(),])\n",
        "\n",
        "    return translated[:-1]\n"
      ],
      "metadata": {
        "id": "BCnzB6lc7Sot"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training"
      ],
      "metadata": {
        "id": "CmKNncaT7Sot"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialisation"
      ],
      "metadata": {
        "id": "3GZ6SfU97Sot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#hyper-parameters\n",
        "num_epochs=100\n",
        "lr=3e-4\n",
        "batch_size=32\n",
        "#input size is embedding dimension\n",
        "input_size,hidden_size=300,1024\n",
        "num_samples=4032\n",
        "num_layers=1\n",
        "freq_threshold=4\n",
        "source_file='/content/drive/MyDrive/Seq2SeqModel/train.de'\n",
        "target_file='/content/drive/MyDrive/Seq2SeqModel/train.en'\n",
        "\n",
        "#dataset\n",
        "train_loader, dataset = get_loader(source_file=source_file,\n",
        "                                   target_file=target_file,\n",
        "                                   num_samples=num_samples,freq_threshold=freq_threshold,batch_size=batch_size,num_workers=8)\n",
        "\n",
        "#model\n",
        "min_loss=np.Inf\n",
        "save_path='/content/drive/MyDrive/Seq2SeqModel/model_attention_withLN'\n",
        "model=Seq2Seq(input_size=input_size,hidden_size=hidden_size,vocab_size_source=len(dataset.vocab.itos_source),vocab_size_target=len(dataset.vocab.itos_target),num_layers=num_layers).to(device)\n",
        "\n",
        "#min_loss=torch.load('/content/drive/MyDrive/Seq2SeqModel/model_attention_withLN.pth',map_location=device)['loss']\n",
        "#model.load_state_dict(torch.load('/content/drive/MyDrive/Seq2SeqModel/model_attention_withLN.pth',map_location=device)['model_state_dict'])\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=lr)\n",
        "criterion=nn.CrossEntropyLoss(ignore_index=dataset.vocab.stoi_target['<PAD>'])"
      ],
      "metadata": {
        "id": "Ju0pZ_6x7Sot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed896f4b-23b1-4a4a-9ef6-dff8d366c243"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0e0537b-9c6b-4c24-c1ec-7a1b72d98a50",
        "id": "xjN8Rvix7Sot"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0003"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c87ce9b8-892c-4fd0-e68c-759e32f5a19e",
        "id": "BN84SUw37Sot"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "inf"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#validation sentence\n",
        "chk_idx=random.randint(0,num_samples)\n",
        "print(f'Dataset Idx: {chk_idx}')\n",
        "source,target=dataset[chk_idx]\n",
        "\n",
        "validation_sentence_source=''\n",
        "for word_idx in source:\n",
        "  validation_sentence_source+=dataset.vocab.itos_source[word_idx.item()]+' '\n",
        "print(f'Source sentence: {validation_sentence_source[:-1]}')\n",
        "\n",
        "validation_sentence_target=''\n",
        "for word_idx in target:\n",
        "  validation_sentence_target+=dataset.vocab.itos_target[word_idx.item()]+' '\n",
        "print(f'Target sentence: {validation_sentence_target[:-1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42d57491-c4e4-4f60-eff7-eefbfdf2576c",
        "id": "WuESugLc7Sot"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Idx: 1763\n",
            "Source sentence: <SOS> ein mann mit blauen shirt und blauer kappe steht vor einem <UNK> cafe <UNK> <UNK> <EOS>\n",
            "Target sentence: <SOS> a young man is standing in front of the candy cafe with a small tree with pink flowers in the front of the building <UNK> <UNK> <EOS>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Checkpoint"
      ],
      "metadata": {
        "id": "V1bKVDxG7Sou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(epoch,model,loss,optimiser,path):\n",
        "  save_path=path+'.pth'\n",
        "  torch.save({\n",
        "      'epoch':epoch,\n",
        "      'model_state_dict':model.state_dict(),\n",
        "      'optimizer_state_dict':optimiser.state_dict(),\n",
        "      'loss':loss\n",
        "  },save_path)"
      ],
      "metadata": {
        "id": "8hMTaED17Sou"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_idx,(source,target) in enumerate(train_loader):\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0kDc1kQv5ot",
        "outputId": "94ca8708-55f6-4a6d-bc7b-b1996f543145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Block"
      ],
      "metadata": {
        "id": "O2Uo3f8Q7Sou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Actual sentence: {validation_sentence_target[:-1]}')\n",
        "initial_teacher_forcer_ratio = 0.7\n",
        "scheduled_sampling_decay = 0.01\n",
        "epoch_losses=[]\n",
        "model.train()\n",
        "num_batches=len(train_loader)\n",
        "for epoch in range(1,num_epochs+1):\n",
        "  batch_losses=[]\n",
        "  print(f'Epoch {epoch} begins:-\\n')\n",
        "  teacher_forcer_ratio = initial_teacher_forcer_ratio / (1 + scheduled_sampling_decay * epoch)\n",
        "  teacher_forcer_ratio = max(teacher_forcer_ratio, 0.0)\n",
        "  for batch_idx,(source_sentences,target_sentences) in enumerate(train_loader):\n",
        "    inputs=source_sentences.to(device)\n",
        "    targets=target_sentences.to(device)\n",
        "\n",
        "    outputs=model(inputs,targets,teacher_forcer_ratio=teacher_forcer_ratio).to(device)\n",
        "\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss=criterion(outputs[1:].reshape(-1,outputs.shape[2]),targets[1:].reshape(-1))\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(),max_norm=1)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    batch_losses.append(loss.item())\n",
        "\n",
        "    if (batch_idx+1)%100==0:\n",
        "      print(f'Epoch {epoch}/{num_epochs}, Batch {batch_idx+1}/{num_batches}, Batch Loss: {batch_losses[-1]:.4f}')\n",
        "\n",
        "      with torch.no_grad():\n",
        "        translated_sentence=model.translate(source,dataset.vocab.itos_target,device)\n",
        "        print(f'Translated sentence: {translated_sentence}\\n')\n",
        "\n",
        "  epoch_losses.append(np.mean(batch_losses))\n",
        "  print(f'\\nEpoch {epoch}/{num_epochs}, Epoch Loss: {epoch_losses[-1]:.4f}')\n",
        "  current_epoch_loss=epoch_losses[-1]\n",
        "  if current_epoch_loss<min_loss:\n",
        "    print(f'Epoch Loss improved from {min_loss:.4f} to {current_epoch_loss:.4f}')\n",
        "    min_loss=current_epoch_loss\n",
        "    save_checkpoint(epoch,model,current_epoch_loss,optimizer,save_path)\n",
        "    print(f'Improved Model saved at \"{save_path}\"\\n')\n",
        "\n",
        "\n",
        "  print(f'Epoch {epoch} ends!!\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f95b88eb-a81b-47ba-c13c-998c41a807d6",
        "id": "-awm-f7x7Sou"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual sentence: <SOS> a young man is standing in front of the candy cafe with a small tree with pink flowers in the front of the building <UNK> <UNK> <EOS>\n",
            "Epoch 1 begins:-\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source_sentences.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCuuTJcyxdzr",
        "outputId": "c0f88d62-a642-48b7-a3a7-c5798b578b40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([19, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Testing Arena"
      ],
      "metadata": {
        "id": "sei8H1jF7Sou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Vocab size of source is: {len(dataset.vocab.itos_source)}, and that of target is: {len(dataset.vocab.itos_target)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8b4ecc6-5c9d-4f75-dbf9-a27f95ff39ca",
        "id": "G--pjlyf7Sou"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size of source is: 1589, and that of target is: 2617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_chk_samples=30\n",
        "for sample in range(1,num_chk_samples+1):\n",
        "  idx=random.randint(0,num_samples)\n",
        "  print(f'Sample no. {sample}, Dataset Index {idx}:-')\n",
        "  validation_sentence_source,target=dataset[idx]\n",
        "  validation_sentence_target=''\n",
        "  for word in target:\n",
        "    validation_sentence_target+=dataset.vocab.itos_target[word.item()]+' '\n",
        "  validation_sentence_target=validation_sentence_target[:-1]\n",
        "  validation_sentence_output=model.translate(validation_sentence_source,dataset.vocab.itos_target,device)\n",
        "\n",
        "  print(f'Target Sentence: {validation_sentence_target}')\n",
        "  print(f'Translated Sentence: {validation_sentence_output}\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67cb686d-6d9d-4e0b-b60f-012103979124",
        "id": "YuTa02Py7Sou"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample no. 1, Dataset Index 1280:-\n",
            "Target Sentence: <SOS> cooks preparing a meal either at a restaurant or culinary school <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> cooks preparing a meal either at a restaurant or culinary school <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 2, Dataset Index 1252:-\n",
            "Target Sentence: <SOS> a man in a white shirt and glasses is holding a glass containing a liquid <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> a man in a white shirt and glasses is holding a glass containing a liquid <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 3, Dataset Index 513:-\n",
            "Target Sentence: <SOS> several children sit on a carnival ride in front of the face of a clown and several fake balloons <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> a children sit on a carnival ride in front of the face of a clown and several fake balloons <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 4, Dataset Index 3944:-\n",
            "Target Sentence: <SOS> a little girl wearing a pink swimsuit and cap is laying by the edge of the water at the ocean <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> a little girl wearing a pink swimsuit and cap is laying by the edge of the water at the ocean <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 5, Dataset Index 2876:-\n",
            "Target Sentence: <SOS> a woman is being seen by a <UNK> who is wearing a flower hair cap <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> a woman is being seen by a <UNK> who is wearing a flower hair cap <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 6, Dataset Index 2499:-\n",
            "Target Sentence: <SOS> two females in black and gray looking up something on a computer <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> two females in black and gray looking up something to a computer <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 7, Dataset Index 2028:-\n",
            "Target Sentence: <SOS> a group of indian people <UNK> one dressed in white and the other in red <UNK> are sitting on a rug <UNK> doing something with tea <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> a group of indian people <UNK> one dressed in white and the other in red <UNK> are sitting on a rug <UNK> doing something <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 8, Dataset Index 1504:-\n",
            "Target Sentence: <SOS> four women wearing dressing and white hats walking along a beach <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> four women wearing dressing and white hats walking along a beach <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 9, Dataset Index 254:-\n",
            "Target Sentence: <SOS> a man <UNK> while facing a woman wearing glasses as they sit inside a restaurant that includes a yellow wall <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> a man <UNK> while facing a woman wearing glasses as they sit inside a restaurant that includes a yellow wall <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 10, Dataset Index 416:-\n",
            "Target Sentence: <SOS> a child <UNK> hitting a baseball into a net <UNK> while two adult men watch <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> a child <UNK> hitting a baseball into a net <UNK> while two adult men watch <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 11, Dataset Index 3710:-\n",
            "Target Sentence: <SOS> people of all ages in hats are <UNK> attention to a person in a blue shirt <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> people of all ages in hats are <UNK> attention to a person in a blue shirt <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 12, Dataset Index 3140:-\n",
            "Target Sentence: <SOS> the brown dog is performing a jump in an obstacle course <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> the brown dog is performing a jump in an obstacle course <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 13, Dataset Index 440:-\n",
            "Target Sentence: <SOS> a barefoot young girl in a pink gown is asleep on a hard wood floor <UNK> her baby doll <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> a barefoot young girl in a pink gown is asleep on a hard wood floor <UNK> her baby doll <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 14, Dataset Index 2678:-\n",
            "Target Sentence: <SOS> a shirtless <UNK> at work is viewed through the weather <UNK> of an <UNK> building <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> a shirtless <UNK> at work is viewed through the weather <UNK> of an <UNK> building <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 15, Dataset Index 256:-\n",
            "Target Sentence: <SOS> a man shovels snow off of a roof while another stands in the contraption that <UNK> them to reach the high place <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> a man shovels snow off of a roof while another stands in the contraption that <UNK> them to reach the high place <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 16, Dataset Index 2405:-\n",
            "Target Sentence: <SOS> three men with <UNK> on their clothing are <UNK> in the field <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> three men with <UNK> on their clothing are <UNK> in the field <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 17, Dataset Index 3132:-\n",
            "Target Sentence: <SOS> a kid dressed in a long <UNK> sleeve shirt with a jersey numbered 11 is passing a bar to a boy in a jersey numbered 12 during a relay race <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> a kid dressed in a long <UNK> sleeve shirt with a jersey numbered 11 is passing a bar to a boy in a jersey numbered 12 during a relay race <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 18, Dataset Index 3439:-\n",
            "Target Sentence: <SOS> a man in a dark jacket with white gloves smokes a cigarette while working with a series of large copper wires <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> a man in a dark jacket with white gloves smokes a cigarette while working with a series of large copper wires <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 19, Dataset Index 2822:-\n",
            "Target Sentence: <SOS> a person in a red shirt is standing <UNK> with arms raised <UNK> at the top of a mountain <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> a person in a red shirt is standing <UNK> with arms raised <UNK> at the top of a mountain <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 20, Dataset Index 1165:-\n",
            "Target Sentence: <SOS> a woman in a black <UNK> robe is standing in a crowd <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> a woman in a black <UNK> robe is standing in a crowd <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 21, Dataset Index 687:-\n",
            "Target Sentence: <SOS> a young boy wearing a <UNK> black and white shirt with his head <UNK> down <UNK> <EOS>\n",
            "Translated Sentence: <SOS> a child wearing a <UNK> is sitting on a red sled outside <UNK> a woman <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 22, Dataset Index 972:-\n",
            "Target Sentence: <SOS> a little blond girl holding a stick walks down a cement path in pink <UNK> <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> a little blond girl holding a stick walks down a cement path in pink <UNK> <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 23, Dataset Index 3847:-\n",
            "Target Sentence: <SOS> an older man wearing a brown jacket and a hat stands outside and reaches into his pocket <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> an older man wearing a brown jacket and a hat stands outside and reaches into his pocket <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 24, Dataset Index 2872:-\n",
            "Target Sentence: <SOS> a boy without a shirt is running in the street while several people stand behind him <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> a boy without a shirt is running in the street while several people stand behind him <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 25, Dataset Index 2885:-\n",
            "Target Sentence: <SOS> a man in a white jacket is checking the blood pressure of a lady <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> a man in a white jacket is checking the blood pressure of a lady <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 26, Dataset Index 2063:-\n",
            "Target Sentence: <SOS> only the letters <UNK> and <UNK> are <UNK> visible as the little boy in the red shirt leans out the window below <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> only the letters <UNK> and <UNK> are <UNK> visible as the little boy in the red shirt leans out the window below <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 27, Dataset Index 1749:-\n",
            "Target Sentence: <SOS> a child lies on the ground near a ball in front of a parked car the leads a line of parked cars on the shoulder of a road <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> a child lies on the ground near a ball in front of a parked car the leads a line of parked cars on the shoulder of a road <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 28, Dataset Index 3067:-\n",
            "Target Sentence: <SOS> a dark <UNK> haired dark <UNK> skinned child sleeps in a chair while holding a blue <UNK> pack <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> a dark <UNK> haired dark <UNK> skinned child sleeps in a chair while holding a blue <UNK> pack <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 29, Dataset Index 2651:-\n",
            "Target Sentence: <SOS> these two young boys with blue and gray shorts <UNK> smile for the camera before they go play outside <UNK> <UNK> <EOS>\n",
            "Translated Sentence: <SOS> these two young boys with blue and gray a <UNK> smile for the camera before they go <UNK> <UNK> <EOS>\n",
            "\n",
            "\n",
            "Sample no. 30, Dataset Index 859:-\n",
            "Target Sentence: <SOS> two dogs playing in a <UNK> field filled with purple flowers <UNK> <EOS>\n",
            "Translated Sentence: <SOS> two dogs playing in a <UNK> field filled with purple flowers <UNK> <EOS>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(float)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d4226a9-531d-437b-9997-98c25a4d8c98",
        "id": "ZG4cXhmO7Sov"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "type"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot([i for i in range(1,len(epoch_losses)+1)],epoch_losses)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs Epochs')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "47rWMPMA7Sov",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "d80d6a2b-8642-43a9-c9ff-d2ec36b3b143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_sentence='a young boy fell into a pool of water'\n",
        "for word in [tok.text.lower() for tok in spacy_eng.tokenizer(target_sentence)]:\n",
        "  if word in dataset.vocab.stoi_target.keys(): print('1',end=' ')\n",
        "  else: print('0',end=' ')\n",
        "print()\n",
        "source_inp='Guten Abend'\n",
        "for word in [tok.text.lower() for tok in spacy_ger.tokenizer(source_inp)]:\n",
        "  if word in dataset.vocab.stoi_source.keys(): print('1',end=' ')\n",
        "  else: print('0',end=' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2HI73H_OvF1",
        "outputId": "6627c096-7415-47e6-b523-5e9163c002e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 1 1 1 1 1 1 1 1 \n",
            "0 0 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source_word_idxs=[dataset.vocab.stoi_source['<SOS>'],]\n",
        "for word in [tok.text.lower() for tok in spacy_ger.tokenizer(source_inp)]:\n",
        "  #print(f'word: {word}')\n",
        "  if word in dataset.vocab.stoi_source.keys():\n",
        "    source_word_idxs.append(dataset.vocab.stoi_source[word])\n",
        "  else:\n",
        "    source_word_idxs.append(dataset.vocab.stoi_source['<UNK>'])\n",
        "source_word_idxs.append(dataset.vocab.stoi_source['<EOS>'])\n",
        "source_word_idxs=torch.tensor(source_word_idxs)\n",
        "\n",
        "translated_sentence=model.translate(source_word_idxs,dataset.vocab.itos_target,device)\n",
        "print(f'Target sentence: {target_sentence}')\n",
        "print(f'Translated sentence: {translated_sentence}')"
      ],
      "metadata": {
        "id": "d5H8FU2ZL1pP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.vocab.stoi_source['baden']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYz5BoH6N39-",
        "outputId": "a27156c6-67e3-47f4-a810-c901c85f5a95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1462"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'sprang' in dataset.vocab.itos_source.values()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ERLRSgkOLuL",
        "outputId": "38a27098-f0af-4ffb-f2ce-b848ead0ea8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    }
  ]
}